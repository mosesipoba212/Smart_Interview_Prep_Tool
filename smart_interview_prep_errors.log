2025-09-16 00:46:21,231 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-16 00:46:21,234 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-16 00:46:21,235 - matplotlib - DEBUG - interactive is False
2025-09-16 00:46:21,235 - matplotlib - DEBUG - platform is win32
2025-09-16 00:46:21,269 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-16 00:46:21,271 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-16 00:46:21,498 - src.utils.error_handler - ERROR - [SYSTEM_STARTUP_FAILED] Missing packages: python-docx
2025-09-16 00:46:23,349 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-16 00:46:23,349 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-16 00:46:23,350 - werkzeug - INFO -  * Restarting with stat
2025-09-16 00:46:24,056 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-16 00:46:24,060 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-16 00:46:24,061 - matplotlib - DEBUG - interactive is False
2025-09-16 00:46:24,061 - matplotlib - DEBUG - platform is win32
2025-09-16 00:46:24,092 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-16 00:46:24,093 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-16 00:46:24,310 - src.utils.error_handler - ERROR - [SYSTEM_STARTUP_FAILED] Missing packages: python-docx
2025-09-16 00:46:26,080 - werkzeug - WARNING -  * Debugger is active!
2025-09-16 00:46:26,082 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-16 00:49:01,594 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-16 00:49:01,598 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-16 00:49:01,599 - matplotlib - DEBUG - interactive is False
2025-09-16 00:49:01,599 - matplotlib - DEBUG - platform is win32
2025-09-16 00:49:01,632 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-16 00:49:01,634 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-16 00:49:01,847 - src.utils.error_handler - ERROR - [SYSTEM_STARTUP_FAILED] Missing packages: python-docx
2025-09-16 00:49:03,620 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-16 00:49:03,620 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-16 00:49:03,621 - werkzeug - INFO -  * Restarting with stat
2025-09-16 00:49:04,319 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-16 00:49:04,322 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-16 00:49:04,323 - matplotlib - DEBUG - interactive is False
2025-09-16 00:49:04,323 - matplotlib - DEBUG - platform is win32
2025-09-16 00:49:04,355 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-16 00:49:04,356 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-16 00:49:04,578 - src.utils.error_handler - ERROR - [SYSTEM_STARTUP_FAILED] Missing packages: python-docx
2025-09-16 00:49:06,318 - werkzeug - WARNING -  * Debugger is active!
2025-09-16 00:49:06,320 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-16 00:49:46,778 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fabfc240-2990-4b42-8b7f-43ccf3131970', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-16 00:49:46,832 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-16 00:49:46,833 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-16 00:49:46,921 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B2E2C8E120>
2025-09-16 00:49:46,921 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B2E285F9D0> server_hostname='api.openai.com' timeout=5.0
2025-09-16 00:49:46,936 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B2E2C75BD0>
2025-09-16 00:49:46,937 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-16 00:49:46,937 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-16 00:49:46,937 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-16 00:49:46,938 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-16 00:49:46,938 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-16 00:49:47,867 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 15 Sep 2025 23:49:47 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_4d72f3d48d9f4b37922f642bdb4f5ca6'), (b'x-envoy-upstream-service-time', b'312'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dg7BocYPBYcHBigBjxjCP3ByGPOhxyOkp5PXUltCxSk-1757980187-1.0.1.1-ZO36T0kNmyiM58hd1OCUCApraeIACZk6_7mIT6T9cUJT0c7cGCu3K5F3zpHelfapylhi5CXlmqSbCZXSfCaLf32ff0bhqA1c22HTbazF1hw; path=/; expires=Tue, 16-Sep-25 00:19:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=BzZBbDKSwaaiJce5K3RxYzxHE1Vn4hwZ03l5FNzj7Ak-1757980187859-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97fc05c86edd60fa-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-16 00:49:47,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-16 00:49:47,868 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-16 00:49:47,868 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-16 00:49:47,868 - httpcore.http11 - DEBUG - response_closed.started
2025-09-16 00:49:47,868 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-16 00:49:47,869 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Mon, 15 Sep 2025 23:49:47 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_4d72f3d48d9f4b37922f642bdb4f5ca6'), ('x-envoy-upstream-service-time', '312'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=dg7BocYPBYcHBigBjxjCP3ByGPOhxyOkp5PXUltCxSk-1757980187-1.0.1.1-ZO36T0kNmyiM58hd1OCUCApraeIACZk6_7mIT6T9cUJT0c7cGCu3K5F3zpHelfapylhi5CXlmqSbCZXSfCaLf32ff0bhqA1c22HTbazF1hw; path=/; expires=Tue, 16-Sep-25 00:19:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=BzZBbDKSwaaiJce5K3RxYzxHE1Vn4hwZ03l5FNzj7Ak-1757980187859-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97fc05c86edd60fa-LHR'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-16 00:49:47,869 - openai._base_client - DEBUG - request_id: req_4d72f3d48d9f4b37922f642bdb4f5ca6
2025-09-16 00:49:47,869 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-16 00:49:47,880 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-16 00:49:47,880 - openai._base_client - DEBUG - 2 retries left
2025-09-16 00:49:47,880 - openai._base_client - INFO - Retrying request to /chat/completions in 0.446668 seconds
2025-09-16 00:49:48,327 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fabfc240-2990-4b42-8b7f-43ccf3131970', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-16 00:49:48,328 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-16 00:49:48,328 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-16 00:49:48,329 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-16 00:49:48,329 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-16 00:49:48,329 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-16 00:49:48,329 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-16 00:49:48,534 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 15 Sep 2025 23:49:48 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_ced78bc1590f4e92b51d333bd5bfc9d7'), (b'x-envoy-upstream-service-time', b'7'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97fc05d11b0860fa-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-16 00:49:48,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-16 00:49:48,534 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-16 00:49:48,534 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-16 00:49:48,534 - httpcore.http11 - DEBUG - response_closed.started
2025-09-16 00:49:48,534 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-16 00:49:48,535 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Mon, 15 Sep 2025 23:49:48 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_ced78bc1590f4e92b51d333bd5bfc9d7', 'x-envoy-upstream-service-time': '7', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97fc05d11b0860fa-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-16 00:49:48,535 - openai._base_client - DEBUG - request_id: req_ced78bc1590f4e92b51d333bd5bfc9d7
2025-09-16 00:49:48,535 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-16 00:49:48,535 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-16 00:49:48,535 - openai._base_client - DEBUG - 1 retry left
2025-09-16 00:49:48,536 - openai._base_client - INFO - Retrying request to /chat/completions in 0.814456 seconds
2025-09-16 00:49:49,351 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fabfc240-2990-4b42-8b7f-43ccf3131970', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-16 00:49:49,351 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-16 00:49:49,352 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-16 00:49:49,352 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-16 00:49:49,352 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-16 00:49:49,352 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-16 00:49:49,352 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-16 00:49:49,549 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 15 Sep 2025 23:49:49 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_b39ca9d4416846f8b7fdc22e94c34c5f'), (b'x-envoy-upstream-service-time', b'8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97fc05d77ea760fa-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-16 00:49:49,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-16 00:49:49,550 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-16 00:49:49,550 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-16 00:49:49,550 - httpcore.http11 - DEBUG - response_closed.started
2025-09-16 00:49:49,550 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-16 00:49:49,550 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Mon, 15 Sep 2025 23:49:49 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_b39ca9d4416846f8b7fdc22e94c34c5f', 'x-envoy-upstream-service-time': '8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97fc05d77ea760fa-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-16 00:49:49,550 - openai._base_client - DEBUG - request_id: req_b39ca9d4416846f8b7fdc22e94c34c5f
2025-09-16 00:49:49,550 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-16 00:49:49,551 - openai._base_client - DEBUG - Re-raising status error
2025-09-16 00:49:49,552 - werkzeug - INFO - 127.0.0.1 - - [16/Sep/2025 00:49:49] "POST /generate-questions HTTP/1.1" 200 -
2025-09-16 00:50:00,769 - werkzeug - INFO - 127.0.0.1 - - [16/Sep/2025 00:50:00] "GET /performance-stats HTTP/1.1" 200 -
2025-09-16 00:50:05,000 - werkzeug - INFO - 127.0.0.1 - - [16/Sep/2025 00:50:05] "GET /study-resources HTTP/1.1" 200 -
2025-09-16 00:50:15,007 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-982f4b3c-a81b-433b-b2b5-1ebd9538fced', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-16 00:50:15,008 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-16 00:50:15,008 - httpcore.connection - DEBUG - close.started
2025-09-16 00:50:15,009 - httpcore.connection - DEBUG - close.complete
2025-09-16 00:50:15,009 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-16 00:50:15,052 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B2E2DD9090>
2025-09-16 00:50:15,052 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B2E285F9D0> server_hostname='api.openai.com' timeout=5.0
2025-09-16 00:50:15,068 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B2E2B23230>
2025-09-16 00:50:15,068 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-16 00:50:15,069 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-16 00:50:15,069 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-16 00:50:15,069 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-16 00:50:15,069 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-16 00:50:15,736 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 15 Sep 2025 23:50:15 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_e2bbbff6cf3d4dbdada7d51bf40f1ed8'), (b'x-envoy-upstream-service-time', b'7'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97fc067839b1cd60-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-16 00:50:15,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-16 00:50:15,737 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-16 00:50:15,737 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-16 00:50:15,737 - httpcore.http11 - DEBUG - response_closed.started
2025-09-16 00:50:15,737 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-16 00:50:15,737 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Mon, 15 Sep 2025 23:50:15 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_e2bbbff6cf3d4dbdada7d51bf40f1ed8', 'x-envoy-upstream-service-time': '7', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97fc067839b1cd60-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-16 00:50:15,737 - openai._base_client - DEBUG - request_id: req_e2bbbff6cf3d4dbdada7d51bf40f1ed8
2025-09-16 00:50:15,738 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-16 00:50:15,738 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-16 00:50:15,738 - openai._base_client - DEBUG - 2 retries left
2025-09-16 00:50:15,738 - openai._base_client - INFO - Retrying request to /chat/completions in 0.494359 seconds
2025-09-16 00:50:16,234 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-982f4b3c-a81b-433b-b2b5-1ebd9538fced', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-16 00:50:16,234 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-16 00:50:16,235 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-16 00:50:16,235 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-16 00:50:16,235 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-16 00:50:16,235 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-16 00:50:16,236 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-16 00:50:17,108 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 15 Sep 2025 23:50:17 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_7ccd096d9a1d421a9e03d2d7a41d82c8'), (b'x-envoy-upstream-service-time', b'227'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97fc067f8c74cd60-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-16 00:50:17,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-16 00:50:17,109 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-16 00:50:17,109 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-16 00:50:17,109 - httpcore.http11 - DEBUG - response_closed.started
2025-09-16 00:50:17,109 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-16 00:50:17,109 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Mon, 15 Sep 2025 23:50:17 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_7ccd096d9a1d421a9e03d2d7a41d82c8', 'x-envoy-upstream-service-time': '227', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97fc067f8c74cd60-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-16 00:50:17,110 - openai._base_client - DEBUG - request_id: req_7ccd096d9a1d421a9e03d2d7a41d82c8
2025-09-16 00:50:17,110 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-16 00:50:17,110 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-16 00:50:17,110 - openai._base_client - DEBUG - 1 retry left
2025-09-16 00:50:17,111 - openai._base_client - INFO - Retrying request to /chat/completions in 0.804800 seconds
2025-09-16 00:50:17,916 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-982f4b3c-a81b-433b-b2b5-1ebd9538fced', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-16 00:50:17,917 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-16 00:50:17,917 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-16 00:50:17,917 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-16 00:50:17,918 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-16 00:50:17,918 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-16 00:50:17,918 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-16 00:50:18,605 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Mon, 15 Sep 2025 23:50:18 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_0e9388525fcd48ddb9028c78ec41b6e1'), (b'x-envoy-upstream-service-time', b'178'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97fc068a08a1cd60-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-16 00:50:18,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-16 00:50:18,606 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-16 00:50:18,606 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-16 00:50:18,606 - httpcore.http11 - DEBUG - response_closed.started
2025-09-16 00:50:18,606 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-16 00:50:18,607 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Mon, 15 Sep 2025 23:50:18 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_0e9388525fcd48ddb9028c78ec41b6e1', 'x-envoy-upstream-service-time': '178', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97fc068a08a1cd60-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-16 00:50:18,607 - openai._base_client - DEBUG - request_id: req_0e9388525fcd48ddb9028c78ec41b6e1
2025-09-16 00:50:18,607 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-16 00:50:18,608 - openai._base_client - DEBUG - Re-raising status error
2025-09-16 00:50:18,608 - werkzeug - INFO - 127.0.0.1 - - [16/Sep/2025 00:50:18] "POST /generate-questions HTTP/1.1" 200 -
2025-09-16 00:50:20,463 - werkzeug - INFO - 127.0.0.1 - - [16/Sep/2025 00:50:20] "POST /scan-emails HTTP/1.1" 200 -
2025-09-16 00:50:24,572 - werkzeug - INFO - 127.0.0.1 - - [16/Sep/2025 00:50:24] "POST /scan-emails HTTP/1.1" 200 -
2025-09-17 19:58:18,649 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 19:58:18,653 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 19:58:18,654 - matplotlib - DEBUG - interactive is False
2025-09-17 19:58:18,654 - matplotlib - DEBUG - platform is win32
2025-09-17 19:58:18,812 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 19:58:18,814 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 19:58:22,419 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 19:58:22,419 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 19:58:22,425 - werkzeug - INFO -  * Restarting with stat
2025-09-17 19:58:23,213 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 19:58:23,217 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 19:58:23,218 - matplotlib - DEBUG - interactive is False
2025-09-17 19:58:23,218 - matplotlib - DEBUG - platform is win32
2025-09-17 19:58:23,252 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 19:58:23,254 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 19:59:02,454 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 19:59:02,457 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 19:59:02,458 - matplotlib - DEBUG - interactive is False
2025-09-17 19:59:02,458 - matplotlib - DEBUG - platform is win32
2025-09-17 19:59:02,493 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 19:59:02,495 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 19:59:04,647 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 19:59:04,647 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 19:59:04,648 - werkzeug - INFO -  * Restarting with stat
2025-09-17 19:59:05,377 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 19:59:05,380 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 19:59:05,381 - matplotlib - DEBUG - interactive is False
2025-09-17 19:59:05,381 - matplotlib - DEBUG - platform is win32
2025-09-17 19:59:05,414 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 19:59:05,416 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 19:59:07,621 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 19:59:07,623 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-17 20:43:23,299 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 20:43:23,305 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 20:43:23,306 - matplotlib - DEBUG - interactive is False
2025-09-17 20:43:23,306 - matplotlib - DEBUG - platform is win32
2025-09-17 20:43:23,502 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 20:43:23,504 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 20:44:11,022 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 20:44:11,029 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 20:44:11,030 - matplotlib - DEBUG - interactive is False
2025-09-17 20:44:11,030 - matplotlib - DEBUG - platform is win32
2025-09-17 20:44:11,223 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 20:44:11,225 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 20:44:11,670 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 20:44:11,671 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 20:44:11,672 - werkzeug - INFO -  * Restarting with stat
2025-09-17 20:44:12,266 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 20:44:12,273 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 20:44:12,274 - matplotlib - DEBUG - interactive is False
2025-09-17 20:44:12,274 - matplotlib - DEBUG - platform is win32
2025-09-17 20:44:12,466 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 20:44:12,468 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 20:44:12,932 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 20:44:12,934 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-17 20:47:19,678 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 20:47:19] "GET /?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758138439658 HTTP/1.1" 200 -
2025-09-17 20:47:20,205 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 20:47:20] "GET /performance-stats HTTP/1.1" 200 -
2025-09-17 20:47:24,505 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 20:47:24] "GET /code-documentation?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758138444499 HTTP/1.1" 200 -
2025-09-17 20:48:10,566 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 20:48:10] "GET / HTTP/1.1" 200 -
2025-09-17 20:48:11,086 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 20:48:11] "GET /performance-stats HTTP/1.1" 200 -
2025-09-17 20:48:57,766 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-17 20:48:57,885 - werkzeug - INFO -  * Restarting with stat
2025-09-17 20:48:58,512 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 20:48:58,518 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 20:48:58,519 - matplotlib - DEBUG - interactive is False
2025-09-17 20:48:58,519 - matplotlib - DEBUG - platform is win32
2025-09-17 20:48:58,731 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 20:48:58,734 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 20:48:59,180 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 20:48:59,182 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-17 20:49:09,299 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-17 20:49:09,442 - werkzeug - INFO -  * Restarting with stat
2025-09-17 20:49:10,084 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 20:49:10,091 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 20:49:10,092 - matplotlib - DEBUG - interactive is False
2025-09-17 20:49:10,092 - matplotlib - DEBUG - platform is win32
2025-09-17 20:49:10,293 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 20:49:10,295 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 20:49:10,980 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 20:49:10,981 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-17 20:49:47,384 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-17 20:49:47,525 - werkzeug - INFO -  * Restarting with stat
2025-09-17 20:49:48,149 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 20:49:48,157 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 20:49:48,158 - matplotlib - DEBUG - interactive is False
2025-09-17 20:49:48,158 - matplotlib - DEBUG - platform is win32
2025-09-17 20:49:48,377 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 20:49:48,379 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 20:49:49,078 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 20:49:49,080 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-17 21:30:15,661 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 21:30:15,681 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 21:30:15,682 - matplotlib - DEBUG - interactive is False
2025-09-17 21:30:15,682 - matplotlib - DEBUG - platform is win32
2025-09-17 21:30:17,138 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 21:30:17,141 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 21:30:18,421 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 21:30:18,421 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 21:30:18,425 - werkzeug - INFO -  * Restarting with stat
2025-09-17 21:30:19,042 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 21:30:19,049 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 21:30:19,049 - matplotlib - DEBUG - interactive is False
2025-09-17 21:30:19,050 - matplotlib - DEBUG - platform is win32
2025-09-17 21:30:19,241 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 21:30:19,243 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 21:30:19,922 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 21:30:19,924 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-17 22:32:32,852 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 22:32:32,859 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 22:32:32,860 - matplotlib - DEBUG - interactive is False
2025-09-17 22:32:32,860 - matplotlib - DEBUG - platform is win32
2025-09-17 22:32:33,064 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 22:32:33,067 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 22:32:33,759 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 22:32:33,759 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 22:32:33,760 - werkzeug - INFO -  * Restarting with stat
2025-09-17 22:32:34,359 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 22:32:34,365 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 22:32:34,366 - matplotlib - DEBUG - interactive is False
2025-09-17 22:32:34,367 - matplotlib - DEBUG - platform is win32
2025-09-17 22:32:34,557 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 22:32:34,559 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 22:32:35,234 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 22:32:35,236 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-17 22:32:54,303 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:32:54] "GET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758144774291 HTTP/1.1" 200 -
2025-09-17 22:32:54,339 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:32:54] "[33mGET /system-diagnostics HTTP/1.1[0m" 404 -
2025-09-17 22:32:57,908 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:32:57] "GET /?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758144777889 HTTP/1.1" 200 -
2025-09-17 22:32:58,427 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:32:58] "GET /performance-stats HTTP/1.1" 200 -
2025-09-17 22:56:59,094 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 22:56:59,094 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 22:56:59,100 - werkzeug - INFO -  * Restarting with stat
2025-09-17 22:57:01,870 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 22:57:01,872 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-17 22:57:01,911 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:57:01] "GET / HTTP/1.1" 200 -
2025-09-17 22:57:01,986 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:57:01] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-09-17 22:57:02,436 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:57:02] "GET /performance-stats HTTP/1.1" 200 -
2025-09-17 22:57:12,698 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:57:12] "POST /scan-emails HTTP/1.1" 200 -
2025-09-17 22:57:18,307 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d633e27c-f75d-49f3-b095-e96d0cc53fff', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-17 22:57:18,368 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-17 22:57:18,369 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-17 22:57:18,404 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002462F7E2E40>
2025-09-17 22:57:18,404 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002462F661450> server_hostname='api.openai.com' timeout=5.0
2025-09-17 22:57:18,423 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002462F846D50>
2025-09-17 22:57:18,423 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-17 22:57:18,423 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-17 22:57:18,423 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-17 22:57:18,424 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-17 22:57:18,424 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-17 22:57:19,182 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 21:57:19 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_39c5678122c8470393fa125da52eff14'), (b'x-envoy-upstream-service-time', b'187'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zm7eqZnKgDs7FGfyXEbc_HjO.38p1oy9hiyCUwLoF9s-1758146239-1.0.1.1-52dwrNmeOByAgp3QTwP.CqRaZ7CR7JqlAPd_8ktA8K3l2jwGP_wm48eHkkcWf7oJyVV_eOleZBFPL2mWBmsIpp7U2RW8OvCcKHPiS5mk0cU; path=/; expires=Wed, 17-Sep-25 22:27:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Na7nwoHPnvFl68amw0ni8zNAy7muGdHAVomXnd8frjU-1758146239069-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980bdbc58f32cd72-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-17 22:57:19,182 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-17 22:57:19,182 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-17 22:57:19,183 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-17 22:57:19,183 - httpcore.http11 - DEBUG - response_closed.started
2025-09-17 22:57:19,183 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-17 22:57:19,183 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Wed, 17 Sep 2025 21:57:19 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_39c5678122c8470393fa125da52eff14'), ('x-envoy-upstream-service-time', '187'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zm7eqZnKgDs7FGfyXEbc_HjO.38p1oy9hiyCUwLoF9s-1758146239-1.0.1.1-52dwrNmeOByAgp3QTwP.CqRaZ7CR7JqlAPd_8ktA8K3l2jwGP_wm48eHkkcWf7oJyVV_eOleZBFPL2mWBmsIpp7U2RW8OvCcKHPiS5mk0cU; path=/; expires=Wed, 17-Sep-25 22:27:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Na7nwoHPnvFl68amw0ni8zNAy7muGdHAVomXnd8frjU-1758146239069-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '980bdbc58f32cd72-LHR'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-17 22:57:19,183 - openai._base_client - DEBUG - request_id: req_39c5678122c8470393fa125da52eff14
2025-09-17 22:57:19,184 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-17 22:57:19,195 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-17 22:57:19,195 - openai._base_client - DEBUG - 2 retries left
2025-09-17 22:57:19,195 - openai._base_client - INFO - Retrying request to /chat/completions in 0.490591 seconds
2025-09-17 22:57:19,686 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d633e27c-f75d-49f3-b095-e96d0cc53fff', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-17 22:57:19,688 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-17 22:57:19,688 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-17 22:57:19,688 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-17 22:57:19,688 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-17 22:57:19,689 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-17 22:57:19,689 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-17 22:57:19,869 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 21:57:19 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_70c212615bff490a9a299ca1aa00b51e'), (b'x-envoy-upstream-service-time', b'8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980bdbcd6f1ecd72-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-17 22:57:19,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-17 22:57:19,870 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-17 22:57:19,870 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-17 22:57:19,870 - httpcore.http11 - DEBUG - response_closed.started
2025-09-17 22:57:19,870 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-17 22:57:19,871 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 21:57:19 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_70c212615bff490a9a299ca1aa00b51e', 'x-envoy-upstream-service-time': '8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980bdbcd6f1ecd72-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-17 22:57:19,871 - openai._base_client - DEBUG - request_id: req_70c212615bff490a9a299ca1aa00b51e
2025-09-17 22:57:19,871 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-17 22:57:19,871 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-17 22:57:19,871 - openai._base_client - DEBUG - 1 retry left
2025-09-17 22:57:19,872 - openai._base_client - INFO - Retrying request to /chat/completions in 0.752966 seconds
2025-09-17 22:57:20,625 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d633e27c-f75d-49f3-b095-e96d0cc53fff', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-17 22:57:20,626 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-17 22:57:20,626 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-17 22:57:20,626 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-17 22:57:20,627 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-17 22:57:20,627 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-17 22:57:20,627 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-17 22:57:22,713 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 21:57:22 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_a1ec609d89cf4f5c8eaf13542961b40d'), (b'x-envoy-upstream-service-time', b'211'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980bdbd34a15cd72-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-17 22:57:22,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-17 22:57:22,714 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-17 22:57:22,714 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-17 22:57:22,714 - httpcore.http11 - DEBUG - response_closed.started
2025-09-17 22:57:22,714 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-17 22:57:22,714 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 21:57:22 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_a1ec609d89cf4f5c8eaf13542961b40d', 'x-envoy-upstream-service-time': '211', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980bdbd34a15cd72-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-17 22:57:22,714 - openai._base_client - DEBUG - request_id: req_a1ec609d89cf4f5c8eaf13542961b40d
2025-09-17 22:57:22,715 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-17 22:57:22,715 - openai._base_client - DEBUG - Re-raising status error
2025-09-17 22:57:22,716 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 22:57:22] "POST /generate-questions HTTP/1.1" 200 -
2025-09-17 23:01:36,639 - werkzeug - INFO -  * Detected change in 'c:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-17 23:01:36,711 - werkzeug - INFO -  * Restarting with stat
2025-09-17 23:01:39,405 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 23:01:39,407 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-17 23:08:12,429 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 23:08:12,429 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 23:08:12,430 - werkzeug - INFO -  * Restarting with stat
2025-09-17 23:08:13,509 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 23:08:13,511 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-17 23:08:27,235 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:08:27] "GET /?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758146907218 HTTP/1.1" 200 -
2025-09-17 23:08:27,755 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:08:27] "GET /performance-stats HTTP/1.1" 200 -
2025-09-17 23:08:30,097 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:08:30] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758146910093 HTTP/1.1[0m" 404 -
2025-09-17 23:10:22,048 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:10:22] "GET / HTTP/1.1" 200 -
2025-09-17 23:10:22,577 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:10:22] "GET /performance-stats HTTP/1.1" 200 -
2025-09-17 23:19:50,577 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:19:50] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758147590573 HTTP/1.1[0m" 404 -
2025-09-17 23:24:21,720 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 23:24:21,720 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 23:24:21,721 - werkzeug - INFO -  * Restarting with stat
2025-09-17 23:24:22,809 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 23:24:22,811 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-17 23:24:36,103 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:24:36] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758147876100 HTTP/1.1[0m" 404 -
2025-09-17 23:44:46,572 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 23:44:46,579 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 23:44:46,580 - matplotlib - DEBUG - interactive is False
2025-09-17 23:44:46,580 - matplotlib - DEBUG - platform is win32
2025-09-17 23:44:46,771 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 23:44:46,773 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 23:44:47,451 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-17 23:44:47,451 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-17 23:44:47,452 - werkzeug - INFO -  * Restarting with stat
2025-09-17 23:44:48,046 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-17 23:44:48,052 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-17 23:44:48,053 - matplotlib - DEBUG - interactive is False
2025-09-17 23:44:48,053 - matplotlib - DEBUG - platform is win32
2025-09-17 23:44:48,239 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-17 23:44:48,242 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-17 23:44:48,903 - werkzeug - WARNING -  * Debugger is active!
2025-09-17 23:44:48,904 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-17 23:45:02,333 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:45:02] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758149102329 HTTP/1.1[0m" 404 -
2025-09-17 23:47:43,965 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:47:43] "GET /?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758149263959 HTTP/1.1" 200 -
2025-09-17 23:47:44,479 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:47:44] "GET /performance-stats HTTP/1.1" 200 -
2025-09-17 23:47:46,976 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:47:46] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758149266971 HTTP/1.1[0m" 404 -
2025-09-17 23:54:31,061 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:54:31] "GET /study-resources HTTP/1.1" 200 -
2025-09-17 23:54:43,422 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:54:43] "POST /scan-emails HTTP/1.1" 200 -
2025-09-17 23:54:58,993 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:54:58] "GET /study-resources HTTP/1.1" 200 -
2025-09-17 23:55:04,823 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-58d29dde-e7be-43c6-8833-ee52de8a3ca4', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-17 23:55:04,885 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-17 23:55:04,886 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-17 23:55:04,920 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029903D02E40>
2025-09-17 23:55:04,920 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029903B81450> server_hostname='api.openai.com' timeout=5.0
2025-09-17 23:55:04,937 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029903D5F110>
2025-09-17 23:55:04,937 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-17 23:55:04,938 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-17 23:55:04,938 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-17 23:55:04,938 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-17 23:55:04,939 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-17 23:55:05,617 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 22:55:05 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_756c6079cc9640e8bbac4de92295ca80'), (b'x-envoy-upstream-service-time', b'222'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=16DotBLiz_8MsHJcZziso03ONNt9cAMPrLbm79gAcp4-1758149705-1.0.1.1-Yk8sTTAHzGozl3fnrVEYstEboDMIv4NumQBTR.XM.ZNMRaPLJHYyQ374cIfSIp4tNnCQjTsdHiVuvYqtiobWTMgyuoZDw9cnGnIVyt48xCU; path=/; expires=Wed, 17-Sep-25 23:25:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=nkebroXuLjtApJP2jw0eoUmWlizkAvwPV4CROcMjGis-1758149705553-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c30678a2a535c-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-17 23:55:05,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-17 23:55:05,619 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-17 23:55:05,619 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-17 23:55:05,619 - httpcore.http11 - DEBUG - response_closed.started
2025-09-17 23:55:05,619 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-17 23:55:05,619 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Wed, 17 Sep 2025 22:55:05 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_756c6079cc9640e8bbac4de92295ca80'), ('x-envoy-upstream-service-time', '222'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=16DotBLiz_8MsHJcZziso03ONNt9cAMPrLbm79gAcp4-1758149705-1.0.1.1-Yk8sTTAHzGozl3fnrVEYstEboDMIv4NumQBTR.XM.ZNMRaPLJHYyQ374cIfSIp4tNnCQjTsdHiVuvYqtiobWTMgyuoZDw9cnGnIVyt48xCU; path=/; expires=Wed, 17-Sep-25 23:25:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=nkebroXuLjtApJP2jw0eoUmWlizkAvwPV4CROcMjGis-1758149705553-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '980c30678a2a535c-LHR'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-17 23:55:05,620 - openai._base_client - DEBUG - request_id: req_756c6079cc9640e8bbac4de92295ca80
2025-09-17 23:55:05,620 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-17 23:55:05,622 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-17 23:55:05,622 - openai._base_client - DEBUG - 2 retries left
2025-09-17 23:55:05,622 - openai._base_client - INFO - Retrying request to /chat/completions in 0.489372 seconds
2025-09-17 23:55:06,112 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-58d29dde-e7be-43c6-8833-ee52de8a3ca4', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-17 23:55:06,113 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-17 23:55:06,113 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-17 23:55:06,113 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-17 23:55:06,114 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-17 23:55:06,114 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-17 23:55:06,114 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-17 23:55:06,272 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 22:55:06 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_25e9eaa678774e3bba8b50d5643c38b7'), (b'x-envoy-upstream-service-time', b'8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c306eec03535c-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-17 23:55:06,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-17 23:55:06,273 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-17 23:55:06,273 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-17 23:55:06,273 - httpcore.http11 - DEBUG - response_closed.started
2025-09-17 23:55:06,273 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-17 23:55:06,273 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 22:55:06 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_25e9eaa678774e3bba8b50d5643c38b7', 'x-envoy-upstream-service-time': '8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c306eec03535c-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-17 23:55:06,274 - openai._base_client - DEBUG - request_id: req_25e9eaa678774e3bba8b50d5643c38b7
2025-09-17 23:55:06,274 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-17 23:55:06,274 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-17 23:55:06,274 - openai._base_client - DEBUG - 1 retry left
2025-09-17 23:55:06,275 - openai._base_client - INFO - Retrying request to /chat/completions in 0.759168 seconds
2025-09-17 23:55:07,034 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-58d29dde-e7be-43c6-8833-ee52de8a3ca4', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-17 23:55:07,035 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-17 23:55:07,035 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-17 23:55:07,036 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-17 23:55:07,036 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-17 23:55:07,036 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-17 23:55:07,036 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-17 23:55:07,935 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 22:55:07 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_c9b17c9a492a4087ae3973f98c4e78a7'), (b'x-envoy-upstream-service-time', b'265'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c3074abbe535c-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-17 23:55:07,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-17 23:55:07,936 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-17 23:55:07,936 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-17 23:55:07,936 - httpcore.http11 - DEBUG - response_closed.started
2025-09-17 23:55:07,936 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-17 23:55:07,937 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 22:55:07 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_c9b17c9a492a4087ae3973f98c4e78a7', 'x-envoy-upstream-service-time': '265', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c3074abbe535c-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-17 23:55:07,937 - openai._base_client - DEBUG - request_id: req_c9b17c9a492a4087ae3973f98c4e78a7
2025-09-17 23:55:07,937 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-17 23:55:07,938 - openai._base_client - DEBUG - Re-raising status error
2025-09-17 23:55:07,938 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:55:07] "POST /generate-questions HTTP/1.1" 200 -
2025-09-17 23:55:10,239 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:55:10] "POST /scan-emails HTTP/1.1" 200 -
2025-09-17 23:58:32,418 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:58:32] "GET /?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758149912097 HTTP/1.1" 200 -
2025-09-17 23:58:32,934 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:58:32] "GET /performance-stats HTTP/1.1" 200 -
2025-09-17 23:58:36,601 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:58:36] "POST /scan-emails HTTP/1.1" 200 -
2025-09-17 23:58:43,270 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:58:43] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758149922952 HTTP/1.1[0m" 404 -
2025-09-17 23:58:49,803 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:58:49] "GET / HTTP/1.1" 200 -
2025-09-17 23:58:50,327 - werkzeug - INFO - 127.0.0.1 - - [17/Sep/2025 23:58:50] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:00:03,366 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-18 00:00:03,372 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-18 00:00:03,373 - matplotlib - DEBUG - interactive is False
2025-09-18 00:00:03,374 - matplotlib - DEBUG - platform is win32
2025-09-18 00:00:03,555 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-18 00:00:03,557 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-18 00:00:04,219 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-18 00:00:04,219 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-18 00:00:04,220 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:00:04,802 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-18 00:00:04,808 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-18 00:00:04,809 - matplotlib - DEBUG - interactive is False
2025-09-18 00:00:04,809 - matplotlib - DEBUG - platform is win32
2025-09-18 00:00:04,991 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-18 00:00:04,993 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-18 00:00:05,652 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:00:05,654 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-18 00:00:15,481 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:00:15] "GET /?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758150015164 HTTP/1.1" 200 -
2025-09-18 00:00:16,000 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:00:16] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:00:18,268 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:00:18] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758150017952 HTTP/1.1[0m" 404 -
2025-09-18 00:00:29,273 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:00:29] "GET / HTTP/1.1" 200 -
2025-09-18 00:00:29,794 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:00:29] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:00:40,873 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-deee1e95-6ba5-4a73-98f5-ea878488cce1', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:00:40,874 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:00:40,874 - httpcore.connection - DEBUG - close.started
2025-09-18 00:00:40,874 - httpcore.connection - DEBUG - close.complete
2025-09-18 00:00:40,875 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-18 00:00:41,886 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029904245F90>
2025-09-18 00:00:41,886 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029903B81450> server_hostname='api.openai.com' timeout=5.0
2025-09-18 00:00:41,904 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029903D12B10>
2025-09-18 00:00:41,905 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:00:41,905 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:00:41,905 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:00:41,905 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:00:41,905 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:00:42,397 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:00:42 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_6f1326ec81dd4b129e9c0cdd4dcf5b9f'), (b'x-envoy-upstream-service-time', b'105'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c38a19af13238-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:00:42,397 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:00:42,397 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:00:42,397 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:00:42,397 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:00:42,398 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:00:42,398 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:00:42 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_6f1326ec81dd4b129e9c0cdd4dcf5b9f', 'x-envoy-upstream-service-time': '105', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c38a19af13238-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:00:42,398 - openai._base_client - DEBUG - request_id: req_6f1326ec81dd4b129e9c0cdd4dcf5b9f
2025-09-18 00:00:42,398 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:00:42,399 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:00:42,399 - openai._base_client - DEBUG - 2 retries left
2025-09-18 00:00:42,399 - openai._base_client - INFO - Retrying request to /chat/completions in 0.478229 seconds
2025-09-18 00:00:42,877 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-deee1e95-6ba5-4a73-98f5-ea878488cce1', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:00:42,878 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:00:42,878 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:00:42,879 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:00:42,879 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:00:42,879 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:00:42,879 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:00:43,038 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:00:42 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_5a39fbfb24e6435c99c468cacc546062'), (b'x-envoy-upstream-service-time', b'6'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c38a7bb413238-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:00:43,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:00:43,038 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:00:43,039 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:00:43,039 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:00:43,039 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:00:43,039 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:00:42 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_5a39fbfb24e6435c99c468cacc546062', 'x-envoy-upstream-service-time': '6', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c38a7bb413238-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:00:43,039 - openai._base_client - DEBUG - request_id: req_5a39fbfb24e6435c99c468cacc546062
2025-09-18 00:00:43,040 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:00:43,040 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:00:43,040 - openai._base_client - DEBUG - 1 retry left
2025-09-18 00:00:43,041 - openai._base_client - INFO - Retrying request to /chat/completions in 0.802700 seconds
2025-09-18 00:00:43,844 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-deee1e95-6ba5-4a73-98f5-ea878488cce1', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:00:43,845 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:00:43,845 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:00:43,845 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:00:43,845 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:00:43,846 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:00:43,846 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:00:44,610 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:00:44 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_1b08ee5f487a49639db1acc2ce10bf5e'), (b'x-envoy-upstream-service-time', b'203'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c38adbbe83238-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:00:44,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:00:44,614 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:00:44,614 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:00:44,615 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:00:44,615 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:00:44,615 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:00:44 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_1b08ee5f487a49639db1acc2ce10bf5e', 'x-envoy-upstream-service-time': '203', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c38adbbe83238-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:00:44,615 - openai._base_client - DEBUG - request_id: req_1b08ee5f487a49639db1acc2ce10bf5e
2025-09-18 00:00:44,615 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:00:44,616 - openai._base_client - DEBUG - Re-raising status error
2025-09-18 00:00:44,617 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:00:44] "POST /generate-questions HTTP/1.1" 200 -
2025-09-18 00:04:32,819 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:32] "GET / HTTP/1.1" 200 -
2025-09-18 00:04:33,340 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:33] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:04:33,509 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:33] "GET / HTTP/1.1" 200 -
2025-09-18 00:04:33,647 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:33] "GET / HTTP/1.1" 200 -
2025-09-18 00:04:34,169 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:34] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:04:43,148 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:43] "POST /scan-emails HTTP/1.1" 200 -
2025-09-18 00:04:52,376 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:52] "GET / HTTP/1.1" 200 -
2025-09-18 00:04:52,896 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:52] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:04:54,651 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ce0b8fab-282b-49ba-af0a-a5229ddece99', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:04:54,652 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:04:54,652 - httpcore.connection - DEBUG - close.started
2025-09-18 00:04:54,653 - httpcore.connection - DEBUG - close.complete
2025-09-18 00:04:54,653 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-18 00:04:54,732 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029903D13E10>
2025-09-18 00:04:54,732 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029903B81450> server_hostname='api.openai.com' timeout=5.0
2025-09-18 00:04:54,748 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002990410DB50>
2025-09-18 00:04:54,748 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:04:54,748 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:04:54,748 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:04:54,749 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:04:54,749 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:04:55,403 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:04:55 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_ad1cfc8967f944939feff971eb0fc39c'), (b'x-envoy-upstream-service-time', b'144'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c3ecded5b8883-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:04:55,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:04:55,404 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:04:55,404 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:04:55,404 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:04:55,404 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:04:55,404 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:04:55 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_ad1cfc8967f944939feff971eb0fc39c', 'x-envoy-upstream-service-time': '144', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c3ecded5b8883-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:04:55,405 - openai._base_client - DEBUG - request_id: req_ad1cfc8967f944939feff971eb0fc39c
2025-09-18 00:04:55,405 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:04:55,405 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:04:55,405 - openai._base_client - DEBUG - 2 retries left
2025-09-18 00:04:55,405 - openai._base_client - INFO - Retrying request to /chat/completions in 0.397537 seconds
2025-09-18 00:04:55,804 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ce0b8fab-282b-49ba-af0a-a5229ddece99', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:04:55,804 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:04:55,805 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:04:55,805 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:04:55,805 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:04:55,805 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:04:55,805 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:04:56,528 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:04:56 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_ec671e77bce542c6b9e7ad9a943f926d'), (b'x-envoy-upstream-service-time', b'206'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c3ed479d28883-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:04:56,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:04:56,529 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:04:56,529 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:04:56,529 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:04:56,529 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:04:56,529 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:04:56 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_ec671e77bce542c6b9e7ad9a943f926d', 'x-envoy-upstream-service-time': '206', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c3ed479d28883-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:04:56,529 - openai._base_client - DEBUG - request_id: req_ec671e77bce542c6b9e7ad9a943f926d
2025-09-18 00:04:56,530 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:04:56,530 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:04:56,530 - openai._base_client - DEBUG - 1 retry left
2025-09-18 00:04:56,530 - openai._base_client - INFO - Retrying request to /chat/completions in 0.783193 seconds
2025-09-18 00:04:57,314 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ce0b8fab-282b-49ba-af0a-a5229ddece99', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:04:57,315 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:04:57,315 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:04:57,315 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:04:57,315 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:04:57,315 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:04:57,316 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:04:57,764 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:04:57 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_72cbc6c373424457bfc377281f971869'), (b'x-envoy-upstream-service-time', b'71'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c3edde8868883-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:04:57,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:04:57,765 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:04:57,765 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:04:57,765 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:04:57,765 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:04:57,765 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:04:57 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_72cbc6c373424457bfc377281f971869', 'x-envoy-upstream-service-time': '71', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c3edde8868883-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:04:57,766 - openai._base_client - DEBUG - request_id: req_72cbc6c373424457bfc377281f971869
2025-09-18 00:04:57,766 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:04:57,766 - openai._base_client - DEBUG - Re-raising status error
2025-09-18 00:04:57,767 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:04:57] "POST /generate-questions HTTP/1.1" 200 -
2025-09-18 00:08:01,118 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-18 00:08:01,118 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-18 00:08:01,119 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:08:02,229 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:08:02,231 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:08:12,902 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:08:12] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758150492582 HTTP/1.1[0m" 404 -
2025-09-18 00:09:10,957 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:09:10] "[33mGET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758150550955 HTTP/1.1[0m" 404 -
2025-09-18 00:12:33,131 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:12:33] "[33mGET /mock-interview HTTP/1.1[0m" 404 -
2025-09-18 00:13:08,508 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:13:08] "GET / HTTP/1.1" 200 -
2025-09-18 00:14:45,531 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:14:45] "[33mGET /mock-interview HTTP/1.1[0m" 404 -
2025-09-18 00:15:13,279 - werkzeug - INFO -  * Detected change in 'c:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-18 00:15:13,365 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:15:13,731 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-18 00:15:13,848 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:15:14,470 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-18 00:15:14,479 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-18 00:15:14,479 - matplotlib - DEBUG - interactive is False
2025-09-18 00:15:14,480 - matplotlib - DEBUG - platform is win32
2025-09-18 00:15:14,690 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-18 00:15:14,692 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-18 00:15:15,392 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:15:15,393 - werkzeug - INFO -  * Debugger PIN: 552-406-529
2025-09-18 00:15:16,142 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:15:16,144 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:16:08,076 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:16:08] "[33mGET /mock-interview HTTP/1.1[0m" 404 -
2025-09-18 00:16:33,065 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-18 00:16:33,066 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-18 00:16:33,066 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:16:34,159 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:16:34,161 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:18:02,088 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-18 00:18:02,089 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-18 00:18:02,090 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:18:03,170 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:18:03,171 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:18:14,190 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:18:14] "GET /?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758151093860 HTTP/1.1" 200 -
2025-09-18 00:18:14,713 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:18:14] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:18:27,703 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-18 00:18:27,761 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:18:28,893 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:18:28,895 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:18:33,494 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:18:33] "GET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758151113183 HTTP/1.1" 200 -
2025-09-18 00:18:42,447 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-e6865c10-87ca-4f13-b134-bdcfb160448e', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality technical interview questions at Easy level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-18 00:18:42,504 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:18:42,504 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-18 00:18:42,542 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027B256E2900>
2025-09-18 00:18:42,542 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027B2525CD70> server_hostname='api.openai.com' timeout=5.0
2025-09-18 00:18:42,559 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027B2593E0D0>
2025-09-18 00:18:42,559 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:18:42,559 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:18:42,560 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:18:42,560 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:18:42,560 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:18:42,793 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:18:42 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_2d2a36475f144367a32f002d52da368b'), (b'x-envoy-upstream-service-time', b'41'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=UTHDKPy3AkUG426if3WdfccgNrJqKXhM6ax0wsSRgeM-1758151122-1.0.1.1-qpzySsHwc9Hh4nzT6mlNxPJyHBdEpnZPSF5wWzTrjNUGdE904byp4EKUmESTzHmMOh8sjMHDGPEkV4D.VeA.Yqjzxq7vjar7b2DU6cF69zQ; path=/; expires=Wed, 17-Sep-25 23:48:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=xCBDuzOvhGb1rBcd8nRxPrRLwgkm0Pfy_DH.keY775o-1758151122734-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c5303b80794bb-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:18:42,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:18:42,795 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:18:42,795 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:18:42,795 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:18:42,795 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:18:42,795 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Wed, 17 Sep 2025 23:18:42 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_2d2a36475f144367a32f002d52da368b'), ('x-envoy-upstream-service-time', '41'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=UTHDKPy3AkUG426if3WdfccgNrJqKXhM6ax0wsSRgeM-1758151122-1.0.1.1-qpzySsHwc9Hh4nzT6mlNxPJyHBdEpnZPSF5wWzTrjNUGdE904byp4EKUmESTzHmMOh8sjMHDGPEkV4D.VeA.Yqjzxq7vjar7b2DU6cF69zQ; path=/; expires=Wed, 17-Sep-25 23:48:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=xCBDuzOvhGb1rBcd8nRxPrRLwgkm0Pfy_DH.keY775o-1758151122734-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '980c5303b80794bb-LHR'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-18 00:18:42,796 - openai._base_client - DEBUG - request_id: req_2d2a36475f144367a32f002d52da368b
2025-09-18 00:18:42,796 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:18:42,797 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:18:42,797 - openai._base_client - DEBUG - 2 retries left
2025-09-18 00:18:42,797 - openai._base_client - INFO - Retrying request to /chat/completions in 0.446878 seconds
2025-09-18 00:18:43,245 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-e6865c10-87ca-4f13-b134-bdcfb160448e', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality technical interview questions at Easy level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-18 00:18:43,246 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:18:43,246 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:18:43,246 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:18:43,246 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:18:43,247 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:18:43,247 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:18:43,613 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:18:43 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_705934b122234646aa627ef534bf07b6'), (b'x-envoy-upstream-service-time', b'186'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c53080a8394bb-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:18:43,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:18:43,614 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:18:43,614 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:18:43,614 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:18:43,614 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:18:43,614 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:18:43 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_705934b122234646aa627ef534bf07b6', 'x-envoy-upstream-service-time': '186', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c53080a8394bb-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:18:43,615 - openai._base_client - DEBUG - request_id: req_705934b122234646aa627ef534bf07b6
2025-09-18 00:18:43,615 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:18:43,615 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:18:43,615 - openai._base_client - DEBUG - 1 retry left
2025-09-18 00:18:43,616 - openai._base_client - INFO - Retrying request to /chat/completions in 0.949395 seconds
2025-09-18 00:18:44,566 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-e6865c10-87ca-4f13-b134-bdcfb160448e', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality technical interview questions at Easy level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-18 00:18:44,566 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:18:44,567 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:18:44,567 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:18:44,567 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:18:44,567 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:18:44,568 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:18:44,810 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:18:44 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_545ee75f13244ef49ae31c47826115cd'), (b'x-envoy-upstream-service-time', b'96'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c53104f0794bb-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:18:44,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:18:44,811 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:18:44,811 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:18:44,811 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:18:44,811 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:18:44,811 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:18:44 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_545ee75f13244ef49ae31c47826115cd', 'x-envoy-upstream-service-time': '96', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c53104f0794bb-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:18:44,812 - openai._base_client - DEBUG - request_id: req_545ee75f13244ef49ae31c47826115cd
2025-09-18 00:18:44,812 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:18:44,812 - openai._base_client - DEBUG - Re-raising status error
2025-09-18 00:18:44,813 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:18:44] "POST /mock-interview/start HTTP/1.1" 200 -
2025-09-18 00:19:04,873 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:19:04] "GET / HTTP/1.1" 200 -
2025-09-18 00:19:05,392 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:19:05] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:19:09,881 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:19:09] "GET / HTTP/1.1" 200 -
2025-09-18 00:19:10,398 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:19:10] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:19:19,607 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-18 00:19:19,607 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:19:19] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-18 00:19:26,237 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-54c3a1a8-a670-44f1-8d98-ab0a1eee2b81', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:19:26,238 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:19:26,238 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-18 00:19:26,299 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027B25AB1450>
2025-09-18 00:19:26,299 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027B2525CB90> server_hostname='api.openai.com' timeout=5.0
2025-09-18 00:19:26,314 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027B25995A70>
2025-09-18 00:19:26,314 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:19:26,315 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:19:26,315 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:19:26,315 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:19:26,315 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:19:26,520 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:19:26 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_664e61293a1a4c26b4d57126f1a59778'), (b'x-envoy-upstream-service-time', b'17'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9wrlNr6z6fsX_2Ox5hMwI4_qoswqHxlfh_BsdP7wtxw-1758151166-1.0.1.1-n5GG0TC3tcEV1jLyK7BficC4aMvaWoAlUOu9kEQSetsVxiStM2iZkhbMt_.7Z...OBrIzU6GROsGufgtqdYjR1hAyqXFSuburYpeXzFzedA; path=/; expires=Wed, 17-Sep-25 23:49:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=UOlk1By.Ij2iIAbchBVSd.UO6ruQjs.FbE6lghWEw.8-1758151166461-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c54152dd93c70-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:19:26,520 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:19:26,520 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:19:26,521 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:19:26,521 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:19:26,521 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:19:26,521 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Wed, 17 Sep 2025 23:19:26 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_664e61293a1a4c26b4d57126f1a59778'), ('x-envoy-upstream-service-time', '17'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=9wrlNr6z6fsX_2Ox5hMwI4_qoswqHxlfh_BsdP7wtxw-1758151166-1.0.1.1-n5GG0TC3tcEV1jLyK7BficC4aMvaWoAlUOu9kEQSetsVxiStM2iZkhbMt_.7Z...OBrIzU6GROsGufgtqdYjR1hAyqXFSuburYpeXzFzedA; path=/; expires=Wed, 17-Sep-25 23:49:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=UOlk1By.Ij2iIAbchBVSd.UO6ruQjs.FbE6lghWEw.8-1758151166461-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '980c54152dd93c70-LHR'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-18 00:19:26,521 - openai._base_client - DEBUG - request_id: req_664e61293a1a4c26b4d57126f1a59778
2025-09-18 00:19:26,521 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:19:26,522 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:19:26,522 - openai._base_client - DEBUG - 2 retries left
2025-09-18 00:19:26,522 - openai._base_client - INFO - Retrying request to /chat/completions in 0.410338 seconds
2025-09-18 00:19:26,933 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-54c3a1a8-a670-44f1-8d98-ab0a1eee2b81', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:19:26,933 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:19:26,934 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:19:26,934 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:19:26,934 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:19:26,934 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:19:26,934 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:19:27,128 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:19:27 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_e18144d5310f48588162fe31df47fccd'), (b'x-envoy-upstream-service-time', b'8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c54191a643c70-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:19:27,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:19:27,129 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:19:27,129 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:19:27,129 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:19:27,129 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:19:27,129 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:19:27 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_e18144d5310f48588162fe31df47fccd', 'x-envoy-upstream-service-time': '8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c54191a643c70-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:19:27,129 - openai._base_client - DEBUG - request_id: req_e18144d5310f48588162fe31df47fccd
2025-09-18 00:19:27,129 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:19:27,130 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:19:27,130 - openai._base_client - DEBUG - 1 retry left
2025-09-18 00:19:27,130 - openai._base_client - INFO - Retrying request to /chat/completions in 0.978568 seconds
2025-09-18 00:19:28,109 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-54c3a1a8-a670-44f1-8d98-ab0a1eee2b81', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert interview coach who creates tailored interview questions.'}, {'role': 'user', 'content': '\n        Generate 10 tailored interview questions for:\n        - Interview Type: \n        - Company: \n        - Position: \n        \n        Please provide questions that are:\n        1. Specific to the role and industry\n        2. Progressive in difficulty\n        3. Include both conceptual and practical aspects\n        4. Relevant to current industry trends\n        \n        Format each question as:\n        Question: [question text]\n        Difficulty: [Easy/Medium/Hard]\n        Category: [specific subcategory]\n        Tips: [brief preparation tips]\n        ---\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 1500, 'temperature': 0.7}}
2025-09-18 00:19:28,110 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:19:28,110 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:19:28,111 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:19:28,111 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:19:28,111 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:19:28,111 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:19:28,571 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:19:28 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_75ca89cec7b846268b8298dba3719c5f'), (b'x-envoy-upstream-service-time', b'89'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c54206b883c70-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:19:28,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:19:28,571 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:19:28,572 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:19:28,572 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:19:28,572 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:19:28,572 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:19:28 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_75ca89cec7b846268b8298dba3719c5f', 'x-envoy-upstream-service-time': '89', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c54206b883c70-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:19:28,572 - openai._base_client - DEBUG - request_id: req_75ca89cec7b846268b8298dba3719c5f
2025-09-18 00:19:28,572 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:19:28,573 - openai._base_client - DEBUG - Re-raising status error
2025-09-18 00:19:28,573 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:19:28] "POST /generate-questions HTTP/1.1" 200 -
2025-09-18 00:21:50,009 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-18 00:21:50,088 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:21:51,223 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:21:51,225 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:22:00,460 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-18 00:22:00,521 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:22:01,343 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:22:01,345 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:22:08,529 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-18 00:22:08,592 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:22:09,446 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:22:09,447 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:22:18,691 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-18 00:22:18,751 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:22:19,575 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:22:19,576 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:22:35,949 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-18 00:22:36,007 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:22:36,824 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:22:36,825 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:22:41,072 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:22:41] "GET /?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758151360750 HTTP/1.1" 200 -
2025-09-18 00:22:41,595 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:22:41] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:26:12,782 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-18 00:26:12,783 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:26:12] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-18 00:26:14,371 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:26:14] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:26:21,844 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:26:21] "GET / HTTP/1.1" 200 -
2025-09-18 00:26:21,926 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:26:21] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-09-18 00:26:22,435 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:26:22] "GET /performance-stats HTTP/1.1" 200 -
2025-09-18 00:26:29,667 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:26:29] "GET /study-resources HTTP/1.1" 200 -
2025-09-18 00:27:09,484 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:27:09] "GET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758151629165 HTTP/1.1" 200 -
2025-09-18 00:28:20,354 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:28:20] "GET /mock-interview?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758151700039 HTTP/1.1" 200 -
2025-09-18 00:39:48,386 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-18 00:39:48,386 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-18 00:39:48,387 - werkzeug - INFO -  * Restarting with stat
2025-09-18 00:39:49,477 - werkzeug - WARNING -  * Debugger is active!
2025-09-18 00:39:49,479 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-18 00:40:03,829 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:40:03] "GET /test-button?id=4b014438-a828-484a-a224-8282469bd34a&vscodeBrowserReqId=1758152403522 HTTP/1.1" 200 -
2025-09-18 00:44:00,892 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f5771171-2f45-4607-9a8c-1f6084d98ec4', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality technical interview questions at Medium level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-18 00:44:00,948 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:44:00,948 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-18 00:44:01,021 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D7BD7881A0>
2025-09-18 00:44:01,021 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D7BBF182D0> server_hostname='api.openai.com' timeout=5.0
2025-09-18 00:44:01,038 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D7BD6B9310>
2025-09-18 00:44:01,038 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:44:01,038 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:44:01,038 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:44:01,039 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:44:01,039 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:44:01,346 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:44:01 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_b640107024b742edab10092a2c6af333'), (b'x-envoy-upstream-service-time', b'124'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pY4I24siv0ll.lvt_6Lx5QXwUoDhy6LImeGNFQCO9L4-1758152641-1.0.1.1-En4KLtGIzmFUfmp57lo.vfnmX9getUjca3UbCwxtZxjcbOK.SAjCqu2YNR6uDPcpN5IYdyTPTODi8MUWTVi.Tx6E8BCl0zSR9CwZf1XiJE8; path=/; expires=Thu, 18-Sep-25 00:14:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=fc.gQOkjKhUfvG1jRQtaNaCU6Bji80Ug8pOD227x_wU-1758152641289-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c78163fd993fe-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:44:01,346 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:44:01,346 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:44:01,347 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:44:01,347 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:44:01,347 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:44:01,347 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Wed, 17 Sep 2025 23:44:01 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_b640107024b742edab10092a2c6af333'), ('x-envoy-upstream-service-time', '124'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=pY4I24siv0ll.lvt_6Lx5QXwUoDhy6LImeGNFQCO9L4-1758152641-1.0.1.1-En4KLtGIzmFUfmp57lo.vfnmX9getUjca3UbCwxtZxjcbOK.SAjCqu2YNR6uDPcpN5IYdyTPTODi8MUWTVi.Tx6E8BCl0zSR9CwZf1XiJE8; path=/; expires=Thu, 18-Sep-25 00:14:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=fc.gQOkjKhUfvG1jRQtaNaCU6Bji80Ug8pOD227x_wU-1758152641289-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '980c78163fd993fe-LHR'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-18 00:44:01,347 - openai._base_client - DEBUG - request_id: req_b640107024b742edab10092a2c6af333
2025-09-18 00:44:01,347 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:44:01,349 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:44:01,349 - openai._base_client - DEBUG - 2 retries left
2025-09-18 00:44:01,349 - openai._base_client - INFO - Retrying request to /chat/completions in 0.466777 seconds
2025-09-18 00:44:01,816 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f5771171-2f45-4607-9a8c-1f6084d98ec4', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality technical interview questions at Medium level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-18 00:44:01,817 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:44:01,818 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:44:01,818 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:44:01,818 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:44:01,818 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:44:01,819 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:44:02,084 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:44:02 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_c0ce9ab6f0b7481390edb589768906aa'), (b'x-envoy-upstream-service-time', b'80'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c781b1a4693fe-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:44:02,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:44:02,085 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:44:02,085 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:44:02,085 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:44:02,085 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:44:02,085 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:44:02 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_c0ce9ab6f0b7481390edb589768906aa', 'x-envoy-upstream-service-time': '80', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c781b1a4693fe-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:44:02,085 - openai._base_client - DEBUG - request_id: req_c0ce9ab6f0b7481390edb589768906aa
2025-09-18 00:44:02,086 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:44:02,086 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-18 00:44:02,086 - openai._base_client - DEBUG - 1 retry left
2025-09-18 00:44:02,086 - openai._base_client - INFO - Retrying request to /chat/completions in 0.901465 seconds
2025-09-18 00:44:02,988 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f5771171-2f45-4607-9a8c-1f6084d98ec4', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality technical interview questions at Medium level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-18 00:44:02,989 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-18 00:44:02,989 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-18 00:44:02,990 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-18 00:44:02,990 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-18 00:44:02,990 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-18 00:44:02,990 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-18 00:44:03,204 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 17 Sep 2025 23:44:03 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_34385f43c59646ca8936891e678333ec'), (b'x-envoy-upstream-service-time', b'37'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'980c78226da893fe-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-18 00:44:03,204 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-18 00:44:03,205 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-18 00:44:03,205 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-18 00:44:03,205 - httpcore.http11 - DEBUG - response_closed.started
2025-09-18 00:44:03,205 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-18 00:44:03,205 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 17 Sep 2025 23:44:03 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_34385f43c59646ca8936891e678333ec', 'x-envoy-upstream-service-time': '37', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '980c78226da893fe-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-18 00:44:03,205 - openai._base_client - DEBUG - request_id: req_34385f43c59646ca8936891e678333ec
2025-09-18 00:44:03,205 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\OneDrive\Smart_Interview_Prep_Tool\.venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-18 00:44:03,206 - openai._base_client - DEBUG - Re-raising status error
2025-09-18 00:44:03,207 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:44:03] "POST /mock-interview/start HTTP/1.1" 200 -
2025-09-18 00:44:23,057 - werkzeug - INFO - 127.0.0.1 - - [18/Sep/2025 00:44:23] "GET /test-button HTTP/1.1" 200 -
2025-09-19 18:33:20,222 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 18:33:20,223 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 18:33:20,228 - werkzeug - INFO -  * Restarting with stat
2025-09-19 18:33:21,303 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 18:33:21,306 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 18:49:16,653 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 18:49:16,654 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 18:49:16,655 - werkzeug - INFO -  * Restarting with stat
2025-09-19 18:49:17,736 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 18:49:17,738 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 18:50:28,158 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:50:28] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758304228140 HTTP/1.1" 200 -
2025-09-19 18:50:28,707 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:50:28] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 18:50:31,146 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:50:31] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 18:50:31,193 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:50:31] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-09-19 18:50:39,867 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:50:39] "POST /mock-interview/start HTTP/1.1" 200 -
2025-09-19 18:51:31,003 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:51:31] "GET / HTTP/1.1" 200 -
2025-09-19 18:51:31,521 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:51:31] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 18:51:44,796 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 18:51:44,797 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:51:44] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 18:51:50,236 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 18:51:50,236 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:51:50] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 18:53:58,358 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 18:53:58,358 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:53:58] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 18:55:17,133 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-19 18:55:19,250 - werkzeug - INFO -  * Restarting with stat
2025-09-19 18:55:20,308 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 18:55:20,310 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 18:55:39,857 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-19 18:55:39,950 - werkzeug - INFO -  * Restarting with stat
2025-09-19 18:55:41,007 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 18:55:41,009 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 18:55:54,214 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:55:54] "GET /test-button?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758304553896 HTTP/1.1" 200 -
2025-09-19 18:55:57,064 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 18:55:57] "GET /mock-interview?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758304557056 HTTP/1.1" 200 -
2025-09-19 18:56:15,964 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-19 18:56:16,070 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:05:49,556 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 19:05:49,557 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:05:49,558 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:05:50,590 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:05:50,592 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:15:09,240 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 19:15:09,240 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:15:09,241 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:15:10,294 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:15:10,295 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:15:16,324 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:16] "GET / HTTP/1.1" 200 -
2025-09-19 19:15:16,855 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:16] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:15:28,225 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:28] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758305728220 HTTP/1.1" 200 -
2025-09-19 19:15:28,739 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:28] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:15:32,657 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 19:15:32,658 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:32] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 19:15:41,351 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 19:15:41,351 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:41] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 19:15:44,891 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:44] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 19:15:48,572 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:48] "[33mGET /internships?status=Applied HTTP/1.1[0m" 404 -
2025-09-19 19:15:54,911 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 19:15:54,911 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:15:54] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 19:16:57,199 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:16:57] "GET /mock-interview?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758305817191 HTTP/1.1" 200 -
2025-09-19 19:17:10,361 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:17:10] "GET /diagnostics?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758305830352 HTTP/1.1" 200 -
2025-09-19 19:17:10,375 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:17:10] "[33mGET /system-diagnostics HTTP/1.1[0m" 404 -
2025-09-19 19:17:26,842 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:17:26] "GET /code-documentation?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758305846833 HTTP/1.1" 200 -
2025-09-19 19:18:07,059 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-19 19:18:07,158 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:18:08,224 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:18:08,226 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:18:13,396 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:18:13] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758305893379 HTTP/1.1" 200 -
2025-09-19 19:18:13,915 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:18:13] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:18:17,707 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:18:17] "GET /diagnostics?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758305897699 HTTP/1.1" 200 -
2025-09-19 19:18:17,716 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:18:17] "GET /system-diagnostics HTTP/1.1" 200 -
2025-09-19 19:18:47,723 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:18:47] "GET /system-diagnostics HTTP/1.1" 200 -
2025-09-19 19:19:01,667 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:19:01] "GET / HTTP/1.1" 200 -
2025-09-19 19:19:02,185 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:19:02] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:19:17,736 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:19:17] "GET /system-diagnostics HTTP/1.1" 200 -
2025-09-19 19:19:39,447 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:19:39] "GET / HTTP/1.1" 200 -
2025-09-19 19:19:40,001 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:19:40] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:20:13,169 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:13] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758306013153 HTTP/1.1" 200 -
2025-09-19 19:20:13,694 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:13] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:20:48,776 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:48] "GET / HTTP/1.1" 200 -
2025-09-19 19:20:49,304 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:49] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:20:50,237 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:50] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 19:20:51,736 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:51] "GET / HTTP/1.1" 200 -
2025-09-19 19:20:52,256 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:52] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:20:53,292 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:53] "GET /diagnostics HTTP/1.1" 200 -
2025-09-19 19:20:53,432 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:20:53] "GET /system-diagnostics HTTP/1.1" 200 -
2025-09-19 19:21:02,553 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:21:02] "GET / HTTP/1.1" 200 -
2025-09-19 19:21:03,068 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:21:03] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:21:04,479 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:21:04] "GET /code-documentation HTTP/1.1" 200 -
2025-09-19 19:21:10,052 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 19:21:10,053 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:21:10] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 19:21:20,007 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:21:20] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:21:22,425 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 19:21:22,425 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:21:22] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 19:21:24,995 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 19:21:24,995 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:21:24] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 19:22:51,764 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:22:51] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758306171748 HTTP/1.1" 200 -
2025-09-19 19:22:52,285 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:22:52] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:23:36,225 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:23:36] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758306216204 HTTP/1.1" 200 -
2025-09-19 19:23:36,748 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:23:36] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:25:50,628 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:25:50] "GET / HTTP/1.1" 200 -
2025-09-19 19:25:51,150 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:25:51] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:25:52,103 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:25:52] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 19:25:53,477 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:25:53] "GET / HTTP/1.1" 200 -
2025-09-19 19:25:53,992 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:25:53] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:25:56,110 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:25:56] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:25:58,042 - src.utils.error_handler - ERROR - [EMAIL_FETCH_FAILED] Email scan failed: 400 Bad Request: Failed to decode JSON object: Expecting value: line 1 column 1 (char 0)
2025-09-19 19:25:58,043 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:25:58] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 19:27:00,018 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\app.py', reloading
2025-09-19 19:27:00,110 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:27:01,202 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:27:01,204 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:27:04,241 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:27:04] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758306424223 HTTP/1.1" 200 -
2025-09-19 19:27:04,766 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:27:04] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:27:43,335 - werkzeug - INFO -  * Detected change in 'C:\\Users\\PC\\OneDrive\\Smart_Interview_Prep_Tool\\src\\email_parser\\simplified_gmail_service.py', reloading
2025-09-19 19:27:43,427 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:27:44,538 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:27:44,540 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:33:52,790 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 19:33:52,791 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:33:52,792 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:33:53,840 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:33:53,841 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:34:23,449 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 19:34:23,449 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:34:23,450 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:34:24,484 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:34:24,486 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:35:36,928 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 19:35:36,928 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:35:36,929 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:35:37,965 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:35:37,966 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:37:27,191 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 19:37:27,191 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:37:27,192 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:37:28,236 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:37:28,238 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:38:01,449 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:38:01] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758307081432 HTTP/1.1" 200 -
2025-09-19 19:38:01,961 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 19:38:01] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 19:39:04,503 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 19:39:04,503 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:39:04,504 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:39:05,552 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:39:05,553 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:44:33,559 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.78:5000
2025-09-19 19:44:33,560 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:44:33,561 - werkzeug - INFO -  * Restarting with stat
2025-09-19 19:44:34,596 - werkzeug - WARNING -  * Debugger is active!
2025-09-19 19:44:34,597 - werkzeug - INFO -  * Debugger PIN: 718-427-143
2025-09-19 19:52:10,061 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 19:52:10,061 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:56:22,542 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 19:56:22,542 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:57:32,137 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 19:57:32,138 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 19:58:25,019 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 19:58:25,019 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 20:00:00,431 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 20:00:00,431 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 20:27:46,898 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 20:27:46,898 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 20:27:48,698 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:27:48] "GET / HTTP/1.1" 200 -
2025-09-19 20:27:48,767 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:27:48] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 20:27:49,219 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:27:49] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 20:27:52,711 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:27:52] "POST /scan-emails HTTP/1.1" 200 -
2025-09-19 20:28:10,639 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:10] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 20:28:11,986 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:11] "POST /scan-emails HTTP/1.1" 200 -
2025-09-19 20:28:14,224 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:14] "POST /scan-emails HTTP/1.1" 200 -
2025-09-19 20:28:21,126 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:21] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 20:28:22,299 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:22] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 20:28:22,330 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:22] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 20:28:29,748 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:29] "POST /mock-interview/start HTTP/1.1" 200 -
2025-09-19 20:28:37,755 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:37] "POST /mock-interview/submit-answer HTTP/1.1" 200 -
2025-09-19 20:28:43,975 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:43] "POST /mock-interview/submit-answer HTTP/1.1" 200 -
2025-09-19 20:28:47,694 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:47] "POST /mock-interview/submit-answer HTTP/1.1" 200 -
2025-09-19 20:28:52,106 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:52] "POST /mock-interview/submit-answer HTTP/1.1" 200 -
2025-09-19 20:28:55,428 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:55] "POST /mock-interview/submit-answer HTTP/1.1" 200 -
2025-09-19 20:28:55,430 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 20:28:55] "POST /mock-interview/report HTTP/1.1" 200 -
2025-09-19 20:55:26,035 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 20:55:26,035 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 20:58:44,365 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-19 20:58:44,386 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-19 20:58:44,387 - matplotlib - DEBUG - interactive is False
2025-09-19 20:58:44,388 - matplotlib - DEBUG - platform is win32
2025-09-19 20:58:45,810 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-19 20:58:45,814 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-19 20:58:46,694 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 20:58:46,694 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 21:00:32,836 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-19 21:00:32,843 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-19 21:00:32,844 - matplotlib - DEBUG - interactive is False
2025-09-19 21:00:32,844 - matplotlib - DEBUG - platform is win32
2025-09-19 21:00:33,031 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-19 21:00:33,033 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-19 21:00:33,452 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 21:00:33,452 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 21:17:27,429 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-19 21:17:27,435 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-19 21:17:27,436 - matplotlib - DEBUG - interactive is False
2025-09-19 21:17:27,436 - matplotlib - DEBUG - platform is win32
2025-09-19 21:17:27,625 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-19 21:17:27,627 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-19 21:17:28,077 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 21:17:28,077 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 21:17:37,854 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:37] "[35m[1mPOST /scan-emails HTTP/1.1[0m" 500 -
2025-09-19 21:17:45,335 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:45] "GET / HTTP/1.1" 200 -
2025-09-19 21:17:45,414 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:45] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:17:45,919 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:45] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:17:50,878 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:50] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 21:17:50,908 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:50] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:17:52,291 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:52] "GET / HTTP/1.1" 200 -
2025-09-19 21:17:52,310 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:52] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:17:52,805 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:52] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:17:53,850 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:53] "GET /diagnostics HTTP/1.1" 200 -
2025-09-19 21:17:53,867 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:53] "GET /system-diagnostics HTTP/1.1" 200 -
2025-09-19 21:17:53,869 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:53] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:17:57,153 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:57] "GET / HTTP/1.1" 200 -
2025-09-19 21:17:57,167 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:57] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:17:57,668 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:57] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:17:59,278 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:17:59] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:18:00,739 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:18:00] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 21:18:00,754 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:18:00] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:18:01,973 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:18:01] "GET / HTTP/1.1" 200 -
2025-09-19 21:18:01,987 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:18:01] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:18:02,487 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:18:02] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:18:04,321 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:18:04] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 21:18:18,302 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:18:18] "[33mGET /internships?status=Applied HTTP/1.1[0m" 404 -
2025-09-19 21:48:16,270 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:48:16] "GET / HTTP/1.1" 200 -
2025-09-19 21:48:16,292 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:48:16] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:48:16,798 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:48:16] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:48:18,910 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:48:18] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 21:58:03,512 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:03] "GET /study-resources?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758315483508 HTTP/1.1" 200 -
2025-09-19 21:58:09,254 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:09] "GET / HTTP/1.1" 200 -
2025-09-19 21:58:09,277 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:09] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:58:09,773 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:09] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:58:11,705 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:11] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 21:58:17,175 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:17] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 21:58:20,127 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:20] "GET / HTTP/1.1" 200 -
2025-09-19 21:58:20,142 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:20] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 21:58:20,653 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:20] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:58:24,643 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:24] "GET / HTTP/1.1" 200 -
2025-09-19 21:58:25,175 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:25] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:58:26,349 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:26] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 21:58:28,561 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:28] "GET / HTTP/1.1" 200 -
2025-09-19 21:58:29,078 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:29] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 21:58:32,232 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:32] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 21:58:35,218 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 21:58:35] "[33mGET /internships?status=Applied HTTP/1.1[0m" 404 -
2025-09-19 22:00:57,929 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:00:57] "GET / HTTP/1.1" 200 -
2025-09-19 22:00:57,949 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:00:57] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:00:58,449 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:00:58] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:00:59,382 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:00:59] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:01:12,324 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:01:12] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:02:02,958 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:02:02] "GET /study-resources?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758315722954 HTTP/1.1" 200 -
2025-09-19 22:03:11,555 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:03:11] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:03:15,689 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:03:15] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:03:32,617 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:03:32] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:04:43,464 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:04:43] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758315883457 HTTP/1.1" 200 -
2025-09-19 22:04:43,988 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:04:43] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:05:29,284 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:29] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:05:36,093 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:36] "GET / HTTP/1.1" 200 -
2025-09-19 22:05:36,121 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:36] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:05:36,618 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:36] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:05:42,533 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:42] "GET / HTTP/1.1" 200 -
2025-09-19 22:05:42,615 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:42] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:05:43,060 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:43] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:05:45,924 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:45] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:05:50,238 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:05:50] "[33mGET /internships?status=Applied HTTP/1.1[0m" 404 -
2025-09-19 22:07:15,186 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-19 22:07:15,193 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-19 22:07:15,194 - matplotlib - DEBUG - interactive is False
2025-09-19 22:07:15,194 - matplotlib - DEBUG - platform is win32
2025-09-19 22:07:15,412 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-19 22:07:15,414 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-19 22:07:15,887 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 22:07:15,887 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 22:07:27,458 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:27] "GET /?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758316047453 HTTP/1.1" 200 -
2025-09-19 22:07:27,979 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:27] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:07:36,689 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:36] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:07:40,253 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:40] "GET /study-resources?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758316060249 HTTP/1.1" 200 -
2025-09-19 22:07:49,304 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:49] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:07:56,460 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:56] "GET / HTTP/1.1" 200 -
2025-09-19 22:07:56,480 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:56] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:07:56,978 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:56] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:07:58,595 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:07:58] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:22:00,445 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:00] "GET /study-resources?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758316920441 HTTP/1.1" 200 -
2025-09-19 22:22:10,711 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:10] "GET / HTTP/1.1" 200 -
2025-09-19 22:22:10,736 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:10] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:22:11,240 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:11] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:22:12,343 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:12] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:22:18,027 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:18] "GET / HTTP/1.1" 200 -
2025-09-19 22:22:18,041 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:18] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:22:18,547 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:18] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:22:19,936 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:19] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:22:21,871 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:21] "GET / HTTP/1.1" 200 -
2025-09-19 22:22:22,399 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:22] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:22:26,882 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:26] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 22:22:28,699 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:28] "GET / HTTP/1.1" 200 -
2025-09-19 22:22:29,223 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:29] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:22:31,733 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:22:31] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:28:21,336 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-19 22:28:21,357 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-19 22:28:21,358 - matplotlib - DEBUG - interactive is False
2025-09-19 22:28:21,359 - matplotlib - DEBUG - platform is win32
2025-09-19 22:28:23,003 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-19 22:28:23,005 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-19 22:28:24,038 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 22:28:24,038 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 22:28:32,929 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:32] "GET / HTTP/1.1" 200 -
2025-09-19 22:28:33,008 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:33] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:28:33,522 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:33] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:28:36,683 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:36] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:28:36,694 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:36] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:28:38,298 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:38] "GET /study-resources?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758317318293 HTTP/1.1" 200 -
2025-09-19 22:28:39,631 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:39] "GET / HTTP/1.1" 200 -
2025-09-19 22:28:39,647 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:39] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:28:40,146 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:40] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:28:44,287 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:44] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:28:44,303 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:28:44] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:29:01,933 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:29:01] "GET / HTTP/1.1" 200 -
2025-09-19 22:29:01,951 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:29:01] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:29:02,447 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:29:02] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:29:07,007 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:29:07] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:29:07,021 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:29:07] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:36:36,804 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-19 22:36:36,810 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-19 22:36:36,811 - matplotlib - DEBUG - interactive is False
2025-09-19 22:36:36,811 - matplotlib - DEBUG - platform is win32
2025-09-19 22:36:37,004 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-19 22:36:37,006 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-19 22:36:37,442 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-19 22:36:37,442 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-19 22:36:39,667 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:39] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:36:39,674 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:39] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:36:40,730 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:40] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:36:40,737 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:40] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:36:51,464 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:51] "GET / HTTP/1.1" 200 -
2025-09-19 22:36:51,486 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:51] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:36:51,983 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:51] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:36:54,413 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:54] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:36:54,434 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:36:54] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:37:46,241 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:37:46] "GET /study-resources?id=31c82e8e-4fb9-442f-8b85-13e5822a397b&vscodeBrowserReqId=1758317866236 HTTP/1.1" 200 -
2025-09-19 22:38:18,920 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:38:18] "GET / HTTP/1.1" 200 -
2025-09-19 22:38:19,433 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:38:19] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:38:24,222 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:38:24] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-19 22:38:29,281 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:38:29] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-19 22:38:50,030 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:38:50] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:39:37,726 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:39:37] "GET / HTTP/1.1" 200 -
2025-09-19 22:39:37,758 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:39:37] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:39:38,265 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:39:38] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:39:47,983 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:39:47] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 22:39:48,011 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:39:48] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:40:10,897 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-19 22:40:10,903 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-19 22:40:10,904 - matplotlib - DEBUG - interactive is False
2025-09-19 22:40:10,904 - matplotlib - DEBUG - platform is win32
2025-09-19 22:40:11,092 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-19 22:40:11,093 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-19 22:40:12,323 - requests_oauthlib.oauth2_session - DEBUG - Generated new state vRCRxMtrZ08AG24ukEJX9ZjQoiNy8d.
2025-09-19 22:40:31,687 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:31] "GET / HTTP/1.1" 200 -
2025-09-19 22:40:31,702 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:31] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:40:32,205 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:32] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:40:47,079 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:47] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 22:40:47,094 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:47] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:40:48,447 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:48] "GET / HTTP/1.1" 200 -
2025-09-19 22:40:48,467 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:48] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:40:48,973 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:48] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:40:51,692 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:51] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:40:52,713 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:52] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 22:40:52,730 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:52] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:40:54,010 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:54] "GET / HTTP/1.1" 200 -
2025-09-19 22:40:54,031 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:54] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:40:54,525 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:54] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:40:58,603 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:40:58] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-19 22:41:02,181 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:41:02] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-19 22:41:03,734 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:41:03] "GET / HTTP/1.1" 200 -
2025-09-19 22:41:03,751 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:41:03] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:41:04,253 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:41:04] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:41:05,210 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:41:05] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-19 22:41:09,210 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:41:09] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-19 22:59:43,379 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:43] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-19 22:59:45,878 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:45] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:59:45,909 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:45] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:59:47,908 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:47] "GET / HTTP/1.1" 200 -
2025-09-19 22:59:47,939 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:47] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:59:48,451 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:48] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:59:53,120 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:53] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:59:54,771 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:54] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:59:55,722 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:55] "GET /mock-interview HTTP/1.1" 200 -
2025-09-19 22:59:55,744 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:55] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:59:56,923 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:56] "GET / HTTP/1.1" 200 -
2025-09-19 22:59:56,938 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:56] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 22:59:57,437 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:57] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 22:59:59,263 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:59] "GET /study-resources HTTP/1.1" 200 -
2025-09-19 22:59:59,276 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 22:59:59] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 23:00:00,263 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 23:00:00] "GET / HTTP/1.1" 200 -
2025-09-19 23:00:00,278 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 23:00:00] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-19 23:00:00,786 - werkzeug - INFO - 127.0.0.1 - - [19/Sep/2025 23:00:00] "GET /performance-stats HTTP/1.1" 200 -
2025-09-19 23:00:42,290 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-19 23:00:42,300 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-19 23:00:42,301 - matplotlib - DEBUG - interactive is False
2025-09-19 23:00:42,301 - matplotlib - DEBUG - platform is win32
2025-09-19 23:00:42,615 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-19 23:00:42,617 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-19 23:00:43,269 - requests_oauthlib.oauth2_session - DEBUG - Generated new state XJWEq5tMh0JxePMSvrwOK1DWfIhh7A.
2025-09-20 21:39:06,943 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-20 21:39:06,967 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-20 21:39:06,968 - matplotlib - DEBUG - interactive is False
2025-09-20 21:39:06,968 - matplotlib - DEBUG - platform is win32
2025-09-20 21:39:08,587 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-20 21:39:08,589 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-20 21:39:10,520 - requests_oauthlib.oauth2_session - DEBUG - Generated new state qjkJyNNUDJqA46RDzsHAwUeztUYoKp.
2025-09-20 21:50:58,541 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-20 21:50:58,549 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-20 21:50:58,550 - matplotlib - DEBUG - interactive is False
2025-09-20 21:50:58,550 - matplotlib - DEBUG - platform is win32
2025-09-20 21:50:58,743 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-20 21:50:58,746 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-20 21:50:59,348 - requests_oauthlib.oauth2_session - DEBUG - Generated new state oob8nzhGV63qHxfitEbvSTREsxjAzR.
2025-09-20 21:51:09,415 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-20 21:51:09,416 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-20 22:13:59,476 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-20 22:13:59,483 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-20 22:13:59,484 - matplotlib - DEBUG - interactive is False
2025-09-20 22:13:59,484 - matplotlib - DEBUG - platform is win32
2025-09-20 22:13:59,688 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-20 22:13:59,690 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-20 22:14:00,292 - requests_oauthlib.oauth2_session - DEBUG - Generated new state lHcWuV2Hwsq7r9HC4h1IjaR4j4DX4c.
2025-09-20 22:14:10,307 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-20 22:14:10,307 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-20 22:14:27,748 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-20 22:14:27,754 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-20 22:14:27,755 - matplotlib - DEBUG - interactive is False
2025-09-20 22:14:27,755 - matplotlib - DEBUG - platform is win32
2025-09-20 22:14:27,948 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-20 22:14:27,950 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-20 22:14:28,492 - requests_oauthlib.oauth2_session - DEBUG - Generated new state bXJ3PDuBnGnvEZ2f8q58oX8zmA0wzR.
2025-09-20 22:14:38,509 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-20 22:14:38,510 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-20 22:14:47,122 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:14:47] "GET / HTTP/1.1" 200 -
2025-09-20 22:14:47,198 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:14:47] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-20 22:14:47,647 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:14:47] "GET /performance-stats HTTP/1.1" 200 -
2025-09-20 22:14:51,834 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:14:51] "GET /performance-stats HTTP/1.1" 200 -
2025-09-20 22:14:55,999 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:14:55] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-20 22:15:03,776 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:15:03] "GET /mock-interview HTTP/1.1" 200 -
2025-09-20 22:15:03,809 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:15:03] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-20 22:15:13,683 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fd394265-5c34-4492-bf92-bbc6c3a56ac2', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality system_design interview questions at Junior level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-20 22:15:13,744 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-20 22:15:13,745 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 22:15:13,842 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002454046E3C0>
2025-09-20 22:15:13,843 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002454035F750> server_hostname='api.openai.com' timeout=5.0
2025-09-20 22:15:13,884 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024540B81A90>
2025-09-20 22:15:13,884 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 22:15:13,884 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 22:15:13,885 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 22:15:13,885 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 22:15:13,885 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 22:15:14,779 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 20 Sep 2025 21:15:14 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_ff7ac93a1a3a47b4ab60f3b9d012ad90'), (b'x-envoy-upstream-service-time', b'289'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FVSwxrIuT9ID1aS3HzTkbSJiQgOl6OsfMQF9g3iIhCQ-1758402914-1.0.1.1-C36CLdlGDMZakGdrJCU4Q90qBAwMpvcJL5OJlDSNAUACYLFYzbaR8PF1El4FReObjNij0tqT_v5Go4VhD2nkkyByfotJgXWP4cEkZdyKwiY; path=/; expires=Sat, 20-Sep-25 21:45:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=h8W2HGzJlK0YIv8VtZTbYiwBU9hv2M5voZThWglDelQ-1758402914177-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'982456401d7e948e-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 22:15:14,780 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-20 22:15:14,780 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 22:15:14,780 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 22:15:14,781 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 22:15:14,781 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 22:15:14,781 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Sat, 20 Sep 2025 21:15:14 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_ff7ac93a1a3a47b4ab60f3b9d012ad90'), ('x-envoy-upstream-service-time', '289'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=FVSwxrIuT9ID1aS3HzTkbSJiQgOl6OsfMQF9g3iIhCQ-1758402914-1.0.1.1-C36CLdlGDMZakGdrJCU4Q90qBAwMpvcJL5OJlDSNAUACYLFYzbaR8PF1El4FReObjNij0tqT_v5Go4VhD2nkkyByfotJgXWP4cEkZdyKwiY; path=/; expires=Sat, 20-Sep-25 21:45:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=h8W2HGzJlK0YIv8VtZTbYiwBU9hv2M5voZThWglDelQ-1758402914177-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '982456401d7e948e-LHR'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-20 22:15:14,781 - openai._base_client - DEBUG - request_id: req_ff7ac93a1a3a47b4ab60f3b9d012ad90
2025-09-20 22:15:14,781 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-20 22:15:14,794 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-20 22:15:14,794 - openai._base_client - DEBUG - 2 retries left
2025-09-20 22:15:14,795 - openai._base_client - INFO - Retrying request to /chat/completions in 0.437365 seconds
2025-09-20 22:15:15,233 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fd394265-5c34-4492-bf92-bbc6c3a56ac2', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality system_design interview questions at Junior level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-20 22:15:15,233 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-20 22:15:15,234 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 22:15:15,234 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 22:15:15,234 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 22:15:15,234 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 22:15:15,234 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 22:15:15,938 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 20 Sep 2025 21:15:15 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_e8f013d84ced49829ad0543e4e5bfb4a'), (b'x-envoy-upstream-service-time', b'196'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'982456488c7a948e-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 22:15:15,939 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-20 22:15:15,939 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 22:15:15,939 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 22:15:15,939 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 22:15:15,939 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 22:15:15,940 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 20 Sep 2025 21:15:15 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_e8f013d84ced49829ad0543e4e5bfb4a', 'x-envoy-upstream-service-time': '196', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '982456488c7a948e-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 22:15:15,940 - openai._base_client - DEBUG - request_id: req_e8f013d84ced49829ad0543e4e5bfb4a
2025-09-20 22:15:15,940 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-20 22:15:15,941 - openai._base_client - DEBUG - Retrying due to status code 429
2025-09-20 22:15:15,941 - openai._base_client - DEBUG - 1 retry left
2025-09-20 22:15:15,941 - openai._base_client - INFO - Retrying request to /chat/completions in 0.896519 seconds
2025-09-20 22:15:16,838 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fd394265-5c34-4492-bf92-bbc6c3a56ac2', 'json_data': {'messages': [{'role': 'user', 'content': '\n        Generate 2 high-quality system_design interview questions at Junior level.\n        \n        Requirements:\n        - Questions should be realistic and commonly asked\n        - Appropriate for the specified difficulty level\n        - If company is specified, tailor to their interview style\n        - Return only the questions, one per line\n        '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 300, 'temperature': 0.7}}
2025-09-20 22:15:16,839 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-20 22:15:16,839 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 22:15:16,840 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 22:15:16,840 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 22:15:16,840 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 22:15:16,840 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 22:15:17,518 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 20 Sep 2025 21:15:16 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_43e2b9e3a6234a86bc1397946ebddbdc'), (b'x-envoy-upstream-service-time', b'206'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'982456528cf1948e-LHR'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 22:15:17,519 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-20 22:15:17,519 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 22:15:17,519 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 22:15:17,519 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 22:15:17,519 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 22:15:17,519 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 20 Sep 2025 21:15:16 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_43e2b9e3a6234a86bc1397946ebddbdc', 'x-envoy-upstream-service-time': '206', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '982456528cf1948e-LHR', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 22:15:17,520 - openai._base_client - DEBUG - request_id: req_43e2b9e3a6234a86bc1397946ebddbdc
2025-09-20 22:15:17,520 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\openai\_base_client.py", line 1027, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-09-20 22:15:17,520 - openai._base_client - DEBUG - Re-raising status error
2025-09-20 22:15:17,521 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:15:17] "POST /mock-interview/start HTTP/1.1" 200 -
2025-09-20 22:15:20,284 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:15:20] "GET / HTTP/1.1" 200 -
2025-09-20 22:15:20,301 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:15:20] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-20 22:15:20,808 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:15:20] "GET /performance-stats HTTP/1.1" 200 -
2025-09-20 22:15:26,216 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:15:26] "GET /study-resources HTTP/1.1" 200 -
2025-09-20 22:15:26,257 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 22:15:26] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-20 23:02:30,345 - httpcore.connection - DEBUG - close.started
2025-09-20 23:02:30,347 - httpcore.connection - DEBUG - close.complete
2025-09-20 23:53:17,453 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-20 23:53:17,472 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-20 23:53:17,473 - matplotlib - DEBUG - interactive is False
2025-09-20 23:53:17,473 - matplotlib - DEBUG - platform is win32
2025-09-20 23:53:18,761 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-20 23:53:18,763 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-20 23:53:20,335 - requests_oauthlib.oauth2_session - DEBUG - Generated new state jezLN9AK6MoWlfXgDUpyBIHGTHBm7j.
2025-09-20 23:53:30,365 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-20 23:53:30,365 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-20 23:55:33,781 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 23:55:33] "GET / HTTP/1.1" 200 -
2025-09-20 23:55:33,851 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 23:55:33] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-20 23:55:34,304 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 23:55:34] "GET /performance-stats HTTP/1.1" 200 -
2025-09-20 23:55:39,943 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 23:55:39] "GET /study-resources HTTP/1.1" 200 -
2025-09-20 23:55:39,975 - werkzeug - INFO - 127.0.0.1 - - [20/Sep/2025 23:55:39] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 00:00:28,790 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:00:28] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 00:00:28,806 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:00:28] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 00:00:34,869 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:00:34] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 00:00:34,927 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:00:34] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 00:01:07,561 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:01:07] "GET / HTTP/1.1" 200 -
2025-09-21 00:01:07,614 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:01:07] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 00:01:08,079 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:01:08] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 00:11:11,042 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-21 00:11:11,048 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-21 00:11:11,049 - matplotlib - DEBUG - interactive is False
2025-09-21 00:11:11,049 - matplotlib - DEBUG - platform is win32
2025-09-21 00:11:11,228 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-21 00:11:11,230 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-21 00:11:11,735 - requests_oauthlib.oauth2_session - DEBUG - Generated new state JanVuupRlvCZUJE7A0IdLH7n2rByT9.
2025-09-21 00:11:21,755 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 00:11:21,755 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 00:11:24,148 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:11:24] "GET /study-resources?id=ca33501a-a5c7-42e2-9927-e2802aa132b5&vscodeBrowserReqId=1758409884144 HTTP/1.1" 200 -
2025-09-21 00:17:46,512 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-21 00:17:46,518 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-21 00:17:46,519 - matplotlib - DEBUG - interactive is False
2025-09-21 00:17:46,519 - matplotlib - DEBUG - platform is win32
2025-09-21 00:17:46,699 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-21 00:17:46,701 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-21 00:17:47,223 - requests_oauthlib.oauth2_session - DEBUG - Generated new state JHOXku2KY3CKJNX4MxWmpqLF1IJn2h.
2025-09-21 00:17:57,232 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 00:17:57,232 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 00:17:59,565 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:17:59] "GET /study-resources?id=ca33501a-a5c7-42e2-9927-e2802aa132b5&vscodeBrowserReqId=1758410279561 HTTP/1.1" 200 -
2025-09-21 00:18:13,296 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:18:13] "GET /study-resources?id=ca33501a-a5c7-42e2-9927-e2802aa132b5&vscodeBrowserReqId=1758410293293 HTTP/1.1" 200 -
2025-09-21 00:18:35,640 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:18:35] "GET / HTTP/1.1" 200 -
2025-09-21 00:18:36,155 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:18:36] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 00:18:39,030 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:18:39] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 00:18:40,486 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:18:40] "GET / HTTP/1.1" 200 -
2025-09-21 00:18:41,001 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:18:41] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 00:18:42,718 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:18:42] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 00:19:11,696 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:19:11] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 00:31:57,740 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-21 00:31:57,746 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-21 00:31:57,747 - matplotlib - DEBUG - interactive is False
2025-09-21 00:31:57,748 - matplotlib - DEBUG - platform is win32
2025-09-21 00:31:57,946 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-21 00:31:57,948 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-21 00:31:58,489 - requests_oauthlib.oauth2_session - DEBUG - Generated new state j69DWMzCr4mB2avvuI9FPnO8iGWqfT.
2025-09-21 00:32:08,508 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 00:32:08,508 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 00:33:08,114 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:33:08] "GET /?id=ca33501a-a5c7-42e2-9927-e2802aa132b5&vscodeBrowserReqId=1758411188108 HTTP/1.1" 200 -
2025-09-21 00:33:08,625 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:33:08] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 00:33:11,971 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:33:11] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 00:33:16,125 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:33:16] "GET / HTTP/1.1" 200 -
2025-09-21 00:33:16,652 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:33:16] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 00:33:21,368 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:33:21] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 00:33:26,666 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 00:33:26] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 19:17:03,484 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-21 19:17:03,508 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-21 19:17:03,509 - matplotlib - DEBUG - interactive is False
2025-09-21 19:17:03,509 - matplotlib - DEBUG - platform is win32
2025-09-21 19:17:05,016 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-21 19:17:05,018 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-21 19:17:06,753 - requests_oauthlib.oauth2_session - DEBUG - Generated new state 8uW8tAc6LACrP3MNwN8l78wMLq2QZh.
2025-09-21 19:17:16,775 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 19:17:16,775 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 19:19:26,010 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:19:26] "GET / HTTP/1.1" 200 -
2025-09-21 19:19:26,082 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:19:26] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:19:26,536 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:19:26] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 19:19:30,199 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:19:30] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 19:19:30,239 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:19:30] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:20:05,173 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:20:05] "GET /analytics HTTP/1.1" 200 -
2025-09-21 19:20:05,190 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:20:05] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 19:20:05,192 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:20:05] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:20:06,658 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:20:06] "GET / HTTP/1.1" 200 -
2025-09-21 19:20:06,678 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:20:06] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:20:07,179 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:20:07] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 19:20:09,532 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:20:09] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:20:09,557 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:20:09] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:26:08,673 - requests_oauthlib.oauth2_session - DEBUG - Generated new state 6RxgGaOxuN3VuM5ZR1FIwcKDomLl4n.
2025-09-21 19:26:18,686 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 19:26:18,687 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 19:26:22,394 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:26:22] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:26:22,433 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:26:22] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:26:34,353 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:26:34] "POST /mock-interview/start HTTP/1.1" 200 -
2025-09-21 19:26:35,818 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:26:35] "GET / HTTP/1.1" 200 -
2025-09-21 19:26:35,874 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:26:35] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:26:36,339 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:26:36] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 19:26:39,167 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:26:39] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:26:39,181 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:26:39] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:30:36,586 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:30:36] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:30:36,602 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:30:36] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:30:37,869 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:30:37] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:30:37,880 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:30:37] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:30:38,761 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:30:38] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:30:40,078 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:30:40] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:30:40,090 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:30:40] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:36:12,394 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:36:12] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:36:12,407 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:36:12] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:36:13,554 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:36:13] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:36:13,566 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:36:13] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:58:02,029 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:58:02] "GET /mock-interview?id=f71c7e38-2c3e-4a01-85b7-2db85ee91dda&vscodeBrowserReqId=1758481082024 HTTP/1.1" 200 -
2025-09-21 19:58:26,915 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:58:26] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:58:26,942 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:58:26] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:58:27,738 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:58:27] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:58:27,749 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:58:27] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 19:58:28,016 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:58:28] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 19:58:28,029 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 19:58:28] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:01:03,917 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-21 20:01:03,923 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-21 20:01:03,924 - matplotlib - DEBUG - interactive is False
2025-09-21 20:01:03,924 - matplotlib - DEBUG - platform is win32
2025-09-21 20:01:04,142 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-21 20:01:04,144 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-21 20:01:04,740 - requests_oauthlib.oauth2_session - DEBUG - Generated new state 0hwNQUBwEtSLYTw7NeV87FsGwFIbdU.
2025-09-21 20:01:08,786 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:08] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:01:08,798 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:08] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:01:10,050 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:10] "GET / HTTP/1.1" 200 -
2025-09-21 20:01:10,071 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:10] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:01:10,569 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:10] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:01:13,274 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:13] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 20:01:13,306 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:13] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:01:14,756 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 20:01:14,757 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 20:01:14,839 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:14] "GET / HTTP/1.1" 200 -
2025-09-21 20:01:14,860 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:14] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:01:15,359 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:15] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:01:17,770 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:17] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:01:17,784 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:17] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:01:18,090 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:01:18] "GET /mock-interview?id=f71c7e38-2c3e-4a01-85b7-2db85ee91dda&vscodeBrowserReqId=1758481278085 HTTP/1.1" 200 -
2025-09-21 20:34:22,137 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:22] "GET / HTTP/1.1" 200 -
2025-09-21 20:34:22,167 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:22] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:34:22,677 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:22] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:34:29,820 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:29] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:34:29,838 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:29] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:34:31,078 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:31] "GET / HTTP/1.1" 200 -
2025-09-21 20:34:31,092 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:31] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:34:31,598 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:31] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:34:32,325 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:32] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:34:32,340 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:32] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:34:34,122 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:34] "GET / HTTP/1.1" 200 -
2025-09-21 20:34:34,141 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:34] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:34:34,641 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:34:34] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:35:05,278 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:35:05] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-21 20:35:25,054 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:35:25] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 20:35:25,081 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:35:25] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:35:26,518 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:35:26] "GET / HTTP/1.1" 200 -
2025-09-21 20:35:26,536 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:35:26] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:35:27,045 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:35:27] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:35:28,987 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:35:28] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:35:29,005 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:35:29] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:36:06,675 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:06] "POST /mock-interview/start HTTP/1.1" 200 -
2025-09-21 20:36:23,138 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:23] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:36:23,184 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:23] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:36:24,187 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:24] "GET / HTTP/1.1" 200 -
2025-09-21 20:36:24,246 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:24] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:36:24,590 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:24] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:36:24,705 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:24] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:36:54,856 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:54] "GET / HTTP/1.1" 200 -
2025-09-21 20:36:54,873 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:54] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:36:55,376 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:55] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:36:57,586 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:57] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:36:59,213 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:59] "GET /study-resources HTTP/1.1" 200 -
2025-09-21 20:36:59,247 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:36:59] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:37:00,443 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:00] "GET / HTTP/1.1" 200 -
2025-09-21 20:37:00,463 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:00] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:37:00,958 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:00] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:37:03,391 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:03] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:37:03,403 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:03] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:37:29,711 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:29] "GET / HTTP/1.1" 200 -
2025-09-21 20:37:29,794 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:29] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:37:30,232 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:30] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:37:49,740 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:49] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:37:49,769 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:49] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:37:52,593 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:52] "GET / HTTP/1.1" 200 -
2025-09-21 20:37:52,615 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:52] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:37:53,108 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:53] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:37:53,988 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:53] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:37:57,604 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:57] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:37:57,619 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:37:57] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:38:05,063 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:38:05] "GET / HTTP/1.1" 200 -
2025-09-21 20:38:05,077 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:38:05] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:38:05,578 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:38:05] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:38:07,139 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:38:07] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:38:07,151 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:38:07] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:39:04,557 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-21 20:39:04,564 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-21 20:39:04,566 - matplotlib - DEBUG - interactive is False
2025-09-21 20:39:04,566 - matplotlib - DEBUG - platform is win32
2025-09-21 20:39:04,781 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-21 20:39:04,784 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-21 20:39:05,382 - requests_oauthlib.oauth2_session - DEBUG - Generated new state ZZkjSsK5NxO0r91Tq2jNB0OfKpBD2B.
2025-09-21 20:39:15,391 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 20:39:15,392 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 20:39:20,770 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:39:20] "GET / HTTP/1.1" 200 -
2025-09-21 20:39:20,851 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:39:20] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 20:39:21,292 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:39:21] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 20:39:27,917 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:39:27] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 20:39:27,963 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 20:39:27] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 21:11:06,396 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 21:11:06] "GET / HTTP/1.1" 200 -
2025-09-21 21:11:06,423 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 21:11:06] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 21:11:06,917 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 21:11:06] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:00:09,995 - requests_oauthlib.oauth2_session - DEBUG - Generated new state qfbcqo5m8AJRBFMcyIqKi7qdv0amWa.
2025-09-21 22:00:20,010 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 22:00:20,010 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 22:00:34,660 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:00:34] "GET / HTTP/1.1" 200 -
2025-09-21 22:00:34,733 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:00:34] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:00:35,180 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:00:35] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:00:40,760 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:00:40] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 22:00:40,794 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:00:40] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:07:31,678 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:31] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 22:07:31,702 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:31] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:07:33,156 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:33] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 22:07:33,179 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:33] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:07:35,211 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:35] "GET / HTTP/1.1" 200 -
2025-09-21 22:07:35,241 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:35] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:07:35,731 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:35] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:07:40,187 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:40] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-21 22:07:45,723 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:45] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:07:46,772 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:07:46] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:46:47,294 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:46:47] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-21 22:46:48,955 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:46:48] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:46:58,781 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:46:58] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 22:46:58,814 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:46:58] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:50:13,619 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:13] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 22:50:13,636 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:13] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:50:14,604 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:14] "GET / HTTP/1.1" 200 -
2025-09-21 22:50:14,642 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:14] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:50:15,125 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:15] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:50:26,408 - requests_oauthlib.oauth2_session - DEBUG - Generated new state 8wzMKMksaKX8QgtC6FbCMY6H3Toqq6.
2025-09-21 22:50:36,427 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 22:50:36,427 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 22:50:41,341 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:41] "GET / HTTP/1.1" 200 -
2025-09-21 22:50:41,428 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:41] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:50:41,864 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:41] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:50:50,801 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:50] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 22:50:50,838 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:50:50] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:54:30,523 - requests_oauthlib.oauth2_session - DEBUG - Generated new state PegR2kXb0KLRdlWi6XZGKYxbL2wm0R.
2025-09-21 22:54:40,529 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 22:54:40,529 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 22:54:45,390 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:54:45] "GET / HTTP/1.1" 200 -
2025-09-21 22:54:45,470 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:54:45] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 22:54:45,913 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:54:45] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 22:54:55,008 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:54:55] "GET /mock-interview HTTP/1.1" 200 -
2025-09-21 22:54:55,058 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 22:54:55] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 23:41:32,828 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:32] "GET / HTTP/1.1" 200 -
2025-09-21 23:41:32,859 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:32] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 23:41:33,368 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:33] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:41:41,254 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:41] "GET / HTTP/1.1" 200 -
2025-09-21 23:41:41,279 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:41] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 23:41:41,776 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:41] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:41:47,035 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:47] "GET / HTTP/1.1" 200 -
2025-09-21 23:41:47,056 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:47] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 23:41:47,562 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:47] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:41:58,102 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:58] "GET / HTTP/1.1" 200 -
2025-09-21 23:41:58,127 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:58] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 23:41:58,625 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:41:58] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:45:00,082 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:45:00] "GET / HTTP/1.1" 200 -
2025-09-21 23:45:00,110 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:45:00] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 23:45:00,611 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:45:00] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:55:10,149 - requests_oauthlib.oauth2_session - DEBUG - Generated new state hfvBLy2z2bRDsjRFCbd980kHZK23T4.
2025-09-21 23:55:20,179 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-21 23:55:20,179 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-21 23:56:10,345 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:56:10] "GET / HTTP/1.1" 200 -
2025-09-21 23:56:10,437 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:56:10] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-21 23:56:10,937 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:56:10] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:56:20,415 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:56:20] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:57:07,329 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:57:07] "POST /log-interview HTTP/1.1" 200 -
2025-09-21 23:57:25,614 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:57:25] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:58:45,637 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:58:45] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:58:58,379 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:58:58] "GET /performance-stats HTTP/1.1" 200 -
2025-09-21 23:58:59,726 - werkzeug - INFO - 127.0.0.1 - - [21/Sep/2025 23:58:59] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:01:25,578 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-22 00:01:25,601 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-22 00:01:25,602 - matplotlib - DEBUG - interactive is False
2025-09-22 00:01:25,602 - matplotlib - DEBUG - platform is win32
2025-09-22 00:01:27,082 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-22 00:01:27,085 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-22 00:01:28,698 - requests_oauthlib.oauth2_session - DEBUG - Generated new state TA0fiUaN4UksjoGWOBU2O2EzH01NsR.
2025-09-22 00:01:38,704 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-22 00:01:38,704 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-22 00:02:51,666 - requests_oauthlib.oauth2_session - DEBUG - Generated new state kXKrhCSY4KX49BaRD5OYWTHqCPDLq9.
2025-09-22 00:03:01,683 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-22 00:03:01,683 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-09-22 00:03:05,403 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:03:05] "GET / HTTP/1.1" 200 -
2025-09-22 00:03:05,487 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:03:05] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-22 00:03:05,929 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:03:05] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:03:10,374 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:03:10] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:03:13,351 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:03:13] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:03:46,201 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:03:46] "POST /log-interview HTTP/1.1" 200 -
2025-09-22 00:03:46,207 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:03:46] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:03:48,371 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:03:48] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:04:05,799 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:04:05] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:04:08,396 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:04:08] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-22 00:04:13,525 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:04:13] "GET /scan-emails?days_back=7 HTTP/1.1" 200 -
2025-09-22 00:04:16,489 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:04:16] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:04:18,332 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:04:18] "GET /study-resources HTTP/1.1" 200 -
2025-09-22 00:04:18,370 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:04:18] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-22 00:05:20,269 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:05:20] "GET /analytics HTTP/1.1" 200 -
2025-09-22 00:05:20,289 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:05:20] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-22 00:05:20,290 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:05:20] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:05:26,750 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:05:26] "GET / HTTP/1.1" 200 -
2025-09-22 00:05:26,769 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:05:26] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-22 00:05:27,268 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:05:27] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:06:12,013 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:06:12] "POST /log-interview HTTP/1.1" 200 -
2025-09-22 00:06:12,018 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:06:12] "GET /performance-stats HTTP/1.1" 200 -
2025-09-22 00:06:22,398 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:06:22] "GET /mock-interview HTTP/1.1" 200 -
2025-09-22 00:06:22,419 - werkzeug - INFO - 127.0.0.1 - - [22/Sep/2025 00:06:22] "[35m[1mGET /favicon.ico HTTP/1.1[0m" 204 -
2025-09-22 00:08:30,359 - matplotlib - DEBUG - matplotlib data path: C:\Users\PC\AppData\Local\Programs\Python\Python313\Lib\site-packages\matplotlib\mpl-data
2025-09-22 00:08:30,365 - matplotlib - DEBUG - CONFIGDIR=C:\Users\PC\.matplotlib
2025-09-22 00:08:30,366 - matplotlib - DEBUG - interactive is False
2025-09-22 00:08:30,367 - matplotlib - DEBUG - platform is win32
2025-09-22 00:08:30,562 - matplotlib - DEBUG - CACHEDIR=C:\Users\PC\.matplotlib
2025-09-22 00:08:30,565 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\Users\PC\.matplotlib\fontlist-v390.json
2025-09-22 00:08:31,115 - requests_oauthlib.oauth2_session - DEBUG - Generated new state aXsRBB5XnpPMgbme0EvNcTxxVlL6li.
2025-09-22 00:08:41,131 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-09-22 00:08:41,131 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
